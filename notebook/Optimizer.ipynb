{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4a617e5",
   "metadata": {},
   "source": [
    "<div align=\"center\"><a href=\"https://colab.research.google.com/github/deepkapha/EarthScanWebinar/blob/main/notebook/Optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4f98370",
   "metadata": {},
   "source": [
    "<center><font size=\"10\">Notebook Outline</font></center>\n",
    "\n",
    "1. **Import Libraries**: In this section, the necessary Python libraries are imported that will be used throughout the notebook.\n",
    "\n",
    "2. **Gradient Descent**: This is a simple and widely used optimization algorithm that iteratively adjusts the parameters in the direction of steepest descent of the loss function. It requires choosing a learning rate that controls the step size at each iteration.\n",
    "\n",
    "3. **Adam**: Adam is an adaptive optimization algorithm that uses a combination of gradient information and a moving average of the parameter updates to adjust the learning rate for each parameter. It is well-suited for large datasets and complex models, and often requires less tuning of the learning rate compared to gradient descent.\n",
    "\n",
    "4. **RMSProp**: RMSProp is another adaptive optimization algorithm that uses a moving average of the squared gradients to adjust the learning rate for each parameter. It is similar to Adam, but does not use a moving average of the parameter updates.\n",
    "\n",
    "5. **Adamax**: Adamax is a variant of Adam that is designed to work well with very sparse gradients, such as those found in text-based models. It uses the infinity norm to normalize the gradient and the parameter updates, which can lead to improved convergence on sparse data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef40f867",
   "metadata": {},
   "source": [
    "# 1. Import the necessaary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4b6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange, asarray\n",
    "import random\n",
    "from numpy import meshgrid\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import rand\n",
    "from numpy.random import seed\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14d67bed",
   "metadata": {},
   "source": [
    "# 2. Gradient Descent Algorithm\n",
    "\n",
    "The gradient descent algorithm is a popular optimization algorithm used to minimize a given objective function by iteratively adjusting the search position in the direction of steepest descent of the function. The algorithm works by computing the gradient of the objective function at the current search position, and then updating the search position by taking a step in the direction of the negative gradient. This process is repeated until a minimum of the function is found or a predetermined stopping criterion is met.\n",
    "\n",
    "In this section, we will look at an implementation of the gradient descent algorithm in Python using three functions: `objective`, `derivative`, and `gradient_descent`. The `objective` function computes the value of the objective function at a given point, the `derivative` function computes the gradient of the objective function at a given point, and the `gradient_descent` function implements the gradient descent algorithm using these two functions.\n",
    "\n",
    "The `objective` function is a simple function that computes the value of the objective function at a given point (x, y). The function takes two arguments, x and y, and returns the value of the objective function evaluated at the point (x, y). This function is used as the objective function in the gradient descent algorithm implemented in `gradient_descent`.\n",
    "\n",
    "The `derivative` function computes the partial derivatives of the objective function with respect to x and y at a given point (x, y). The function takes two arguments, x and y, and returns a 1D array containing the partial derivatives of the objective function with respect to x and y, respectively. This function is used to compute the gradient of the objective function in the gradient descent algorithm implemented in `gradient_descent`.\n",
    "\n",
    "The `gradient_descent` function is the main function that implements the gradient descent algorithm. The function takes five arguments: the `objective` function, the `derivative` function, an array of bounds specifying the search space, the number of iterations to run the algorithm, the step size to use when updating the search position, and the momentum to use when updating the search position. The function returns a list of candidate solutions found by the algorithm.\n",
    "\n",
    "The `gradient_descent` function works by generating an initial point within the specified bounds and evaluating the objective function at that point. It then iteratively computes the gradient of the objective function at the current search position using the `derivative` function, updates the search position using the gradient and the specified step size and momentum, and evaluates the objective function at the new search position. This process is repeated for the specified number of iterations, and the function returns a list of candidate solutions found during the search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of plotting gradient descent with momentum for a one-dimensional function\n",
    "# objective function\n",
    "def objective(x, y):\n",
    "    \"\"\"\n",
    "    Compute the value of the objective function at the given point (x, y).\n",
    "\n",
    "    This function is used as the objective function in the gradient descent algorithm implemented in `gradient_descent`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float\n",
    "        The x-coordinate of the point at which to evaluate the function.\n",
    "    y : float\n",
    "        The y-coordinate of the point at which to evaluate the function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The value of the objective function at the point (x, y).\n",
    "    \"\"\"\n",
    "    return x**2.0 + y**2.0\n",
    " \n",
    "# derivative of objective function\n",
    "def derivative(x, y):\n",
    "    \"\"\"\n",
    "    Compute the partial derivatives of the objective function with respect to x and y at the given point (x, y).\n",
    "\n",
    "    This function is used to compute the gradient of the objective function in the gradient descent algorithm implemented in `gradient_descent`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float\n",
    "        The x-coordinate of the point at which to evaluate the partial derivatives.\n",
    "    y : float\n",
    "        The y-coordinate of the point at which to evaluate the partial derivatives.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        A 1D array containing the partial derivatives of the objective function with respect to x and y, respectively.\n",
    "    \"\"\"\n",
    "    return asarray([x * 2.0, y * 2.0])\n",
    "\n",
    "# gradient descent algorithm\n",
    "def gradient_descent(objective, derivative, bounds, n_iter, step_size, momentum):\n",
    "    \"\"\"\n",
    "        Minimize a given objective function using the gradient descent algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        objective : function\n",
    "            The objective function to minimize.\n",
    "        derivative : function\n",
    "            A function that computes the gradient of the objective function.\n",
    "        bounds : ndarray\n",
    "            An array of shape (n_dimensions, 2) specifying the lower and upper bounds for each dimension of the search space.\n",
    "        n_iter : int\n",
    "            The number of iterations to run the algorithm.\n",
    "        step_size : float\n",
    "            The step size to use when updating the search position.\n",
    "        momentum : float\n",
    "            The momentum to use when updating the search position.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            A list of candidate solutions found by the algorithm.\n",
    "    \"\"\"\n",
    "\t# track all solutions\n",
    "    solutions = list()\n",
    "    # generate an initial point\n",
    "    x = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "    score = objective(x[0], x[1])\n",
    "\t# keep track of the change\n",
    "    change = 0.0\n",
    "\t# run the gradient descent\n",
    "    for t in range(n_iter):\n",
    "\t\t# calculate gradient\n",
    "        gradient = derivative(x[0], x[1])\n",
    "        for i in range(x.shape[0]):\n",
    "\t\t# calculate update\n",
    "            new_change = step_size * gradient[i] + momentum * change\n",
    "            \n",
    "\t\t# take a step\n",
    "            x[i] = x[i] - new_change\n",
    "\t\t# save the change\n",
    "            change = new_change\n",
    "\t\t# evaluate candidate point\n",
    "        \n",
    "            solution_eval = objective(x[0], x[1])\n",
    "\t\t# store solution\n",
    "            solutions.append(x.copy())\n",
    "            #scores.append(solution_eval)\n",
    "\t\t# report progress\n",
    "        print('>%d f(%s) = %.5f' % (t, x, solution_eval))\n",
    "    return solutions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dda139f1",
   "metadata": {},
   "source": [
    "#### Performing Gradient Descent Search with Momentum\n",
    "\n",
    "In this code example, we perform a gradient descent search with momentum using the `gradient_descent` function implemented in the previous section. The search is performed on the `objective` function defined earlier, with the `derivative` function used to compute the gradient of the objective function at each search position.\n",
    "\n",
    "To perform the search, we first seed the pseudo-random number generator for reproducibility, then define the range for the input variables using the `bounds` array. We also define the total number of iterations to run the search (`n_iter`), the step size to use when updating the search position (`step_size`), and the momentum to use when updating the search position (`momentum`).\n",
    "\n",
    "We then call the `gradient_descent` function with these parameters, along with the `objective` and `derivative` functions, to perform the search. The function returns a list of candidate solutions found during the search, which we can use to analyze the behavior of the algorithm.\n",
    "\n",
    "Overall, this code example demonstrates how to use the `gradient_descent` function to perform a gradient descent search with momentum on a given objective function, and shows how the behavior of the algorithm can be controlled using the step size and momentum parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f14ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed the pseudo random number generator\n",
    "seed(4)\n",
    "# define range for input\n",
    "bounds = asarray([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "# define the total iterations\n",
    "n_iter = 30\n",
    "# define the step size\n",
    "step_size = 0.1\n",
    "# define momentum\n",
    "momentum = 0.3\n",
    "# perform the gradient descent search with momentum\n",
    "solutions = gradient_descent(objective, derivative, bounds, n_iter, step_size, momentum)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5012264a",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent Algorithm with Adam Optimization\n",
    "In this code, we're implementing the Adam optimization algorithm for gradient descent. This algorithm is an extension of the standard gradient descent algorithm that includes two additional momentum terms, known as first and second moments, to better adapt the learning rate based on the magnitude of the gradients.\n",
    "\n",
    "The `objective` function being minimized is defined by the `objective()` function, which takes in two variables x and y and returns their squared sum. \n",
    "\n",
    "The `derivative` function calculates the gradient of the `objective` function at any given point x and y, and returns a 2D array of the partial derivatives with respect to x and y.\n",
    "\n",
    "To start, the algorithm generates an initial point randomly within the bounds defined by the bounds parameter. The `n_iter` parameter specifies the number of iterations the algorithm will run for. The `alpha`, `beta1`, `beta2`, and `eps` parameters are hyperparameters that control the step size, first and second momentum decay rates, and a small value added to the denominator to avoid division by zero.\n",
    "\n",
    "During each iteration, the gradient g is calculated using the `derivative()` function. The first and second moments m and v are then updated using the current gradient and the hyperparameters. The updated moments are used to calculate new \"momentum-corrected\" estimates of the gradient mhat and vhat, which are then used to update the point x along the gradient direction. The process repeats until the specified number of iterations is reached.\n",
    "\n",
    "The solutions list stores the updated points x and their corresponding scores, which are printed out during each iteration to track the progress of the algorithm. The final list of solutions is returned at the end of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45fb4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent optimization with adam for a two-dimensional test function\n",
    "\n",
    " \n",
    "# objective function\n",
    "def objective(x, y):\n",
    "    \"\"\"\n",
    "    Objective function to be optimized using gradient descent with ADAM optimizer.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: float\n",
    "        The input value for the x-coordinate.\n",
    "    y: float\n",
    "        The input value for the y-coordinate.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float:\n",
    "        The output value of the objective function for the given input values.\n",
    "    \"\"\"\n",
    "    return x**2.0 + y**2.0\n",
    " \n",
    "# derivative of objective function\n",
    "def derivative(x, y):\n",
    "    \"\"\"\n",
    "    Gradient of the objective function with respect to the input values x and y.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: float\n",
    "        The input value for the x-coordinate.\n",
    "    y: float\n",
    "        The input value for the y-coordinate.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray:\n",
    "        A numpy array with two elements representing the partial derivatives of the objective\n",
    "        function with respect to x and y, respectively.\n",
    "    \"\"\"\n",
    "    return asarray([x * 2.0, y * 2.0])\n",
    " \n",
    "# gradient descent algorithm with adam\n",
    "def adam(objective, derivative, bounds, n_iter, alpha, beta1, beta2, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Gradient descent optimization with Adam optimizer.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    objective: function\n",
    "        The objective function to be optimized.\n",
    "    derivative: function\n",
    "        The derivative function of the objective function.\n",
    "    bounds: numpy.ndarray\n",
    "        A numpy array with shape (2, 2) representing the bounds for the input variables.\n",
    "        Each row corresponds to one of the input variables, with the first column giving the\n",
    "        lower bound and the second column giving the upper bound.\n",
    "    n_iter: int\n",
    "        The number of iterations for which to run the optimization algorithm.\n",
    "    alpha: float\n",
    "        The learning rate or step size parameter for the optimization algorithm.\n",
    "    beta1: float\n",
    "        The weighting factor for the moving average of the gradient in the Adam optimizer.\n",
    "    beta2: float\n",
    "        The weighting factor for the moving average of the squared gradient in the Adam optimizer.\n",
    "    eps: float, optional\n",
    "        A small constant value to prevent division by zero.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list:\n",
    "        A list of numpy arrays, where each array represents the input values for a candidate\n",
    "        solution found during the optimization process.\n",
    "    \"\"\"\n",
    " # generate an initial point\n",
    "    solutions = list()\n",
    "    x = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "    score = objective(x[0], x[1])\n",
    " # initialize first and second moments\n",
    "    m = [0.0 for _ in range(bounds.shape[0])]\n",
    "    v = [0.0 for _ in range(bounds.shape[0])]\n",
    " # run the gradient descent updates\n",
    "    for t in range(n_iter):\n",
    " # calculate gradient g(t)\n",
    "        g = derivative(x[0], x[1])\n",
    "     # build a solution one variable at a time\n",
    "        for i in range(x.shape[0]):\n",
    "         # m(t) = beta1 * m(t-1) + (1 - beta1) * g(t)\n",
    "            m[i] = beta1 * m[i] + (1.0 - beta1) * g[i]\n",
    "         # v(t) = beta2 * v(t-1) + (1 - beta2) * g(t)^2\n",
    "            v[i] = beta2 * v[i] + (1.0 - beta2) * g[i]**2\n",
    "         # mhat(t) = m(t) / (1 - beta1(t))\n",
    "            mhat = m[i] / (1.0 - beta1**(t+1))\n",
    "         # vhat(t) = v(t) / (1 - beta2(t))\n",
    "            vhat = v[i] / (1.0 - beta2**(t+1))\n",
    "         # x(t) = x(t-1) - alpha * mhat(t) / (sqrt(vhat(t)) + eps)\n",
    "            x[i] = x[i] - alpha * mhat / (sqrt(vhat) + eps)\n",
    "         # evaluate candidate point\n",
    "            score = objective(x[0], x[1])\n",
    "            solutions.append(x.copy())\n",
    "         # report progress\n",
    "            print('>%d f(%s) = %.5f' % (t, x, score))\n",
    "    return solutions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cecb96ac",
   "metadata": {},
   "source": [
    "We begin by setting the seed for the pseudo-random number generator to ensure reproducibility of the results. We define the range of inputs for our `objective` function, which is a two-dimensional function.\n",
    "\n",
    "Next, we define the number of iterations, step size, and factors for average gradient and average squared gradient. These values are used to perform the gradient descent search with Adam optimization. The `adam()` function takes in the `objective()` and `derivative()` functions, bounds, number of iterations, step size, and the factors for average gradient and average squared gradient.\n",
    "\n",
    "Once the search is complete, the best solution and its corresponding score are printed. We then plot the contour plot of the objective function with 50 levels and a jet color scheme. The sample points are plotted as black circles, and the path of the optimization algorithm is plotted as a white line connecting the points. Finally, we display the plot using plt.show()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed the pseudo random number generator\n",
    "seed(1)\n",
    "# define range for input\n",
    "bounds = asarray([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "# define the total iterations\n",
    "n_iter = 60\n",
    "# steps size\n",
    "alpha = 0.02\n",
    "# factor for average gradient\n",
    "beta1 = 0.8\n",
    "# factor for average squared gradient\n",
    "beta2 = 0.999\n",
    "# perform the gradient descent search with adam\n",
    "solutions = adam(objective, derivative, bounds, n_iter, alpha, beta1, beta2)\n",
    "print('Done!')\n",
    "#print('f(%s) = %f' % (best, score))\n",
    "# plot the sample as black circles\n",
    "# sample input range uniformly at 0.1 increments\n",
    "xaxis = arange(bounds[0,0], bounds[0,1], 0.1)\n",
    "yaxis = arange(bounds[1,0], bounds[1,1], 0.1)\n",
    "# create a mesh from the axis\n",
    "x, y = meshgrid(xaxis, yaxis)\n",
    "# compute targets\n",
    "results = objective(x, y)\n",
    "# create a filled contour plot with 50 levels and jet color scheme\n",
    "plt.contourf(x, y, results, levels=50, cmap='jet')\n",
    "# plot the sample as black circles\n",
    "solutions = asarray(solutions)\n",
    "plt.plot(solutions[:, 0], solutions[:, 1], '.-', color='w')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29c08280",
   "metadata": {},
   "source": [
    "# 4. Gradient Descent Algorithm with RMSprop Optimization\n",
    "In this code, we're implementing the RMSprop optimization algorithm for gradient descent. This algorithm is an adaptive learning rate method that adjusts the step size of the gradients based on the magnitude of recent gradients.\n",
    "\n",
    "The `objective` function being minimized is defined by the `objective()` function, which takes in two variables x and y and returns their squared sum.\n",
    "\n",
    "The `derivative` function calculates the gradient of the objective function at any given point x and y, and returns a 2D array of the partial derivatives with respect to x and y.\n",
    "\n",
    "To start, the algorithm generates an initial point randomly within the bounds defined by the bounds parameter. The `n_iter` parameter specifies the number of iterations the algorithm will run for. The `alpha` and `eps` parameters are hyperparameters that control the step size and a small value added to the denominator to avoid division by zero.\n",
    "\n",
    "During each iteration, the gradient `g` is calculated using the `derivative()` function. The gradient is then squared and a running average of the squared gradients is maintained using the current and previous gradients, decayed by the hyperparameter `alpha`. The updated running average is used to normalize the gradient, which is then used to update the point x along the gradient direction. The process repeats until the specified number of iterations is reached.\n",
    "\n",
    "The solutions list stores the updated points x and their corresponding scores, which are printed out during each iteration to track the progress of the algorithm. The final list of solutions is returned at the end of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d1fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of plotting the rmsprop search on a contour plot of the test function\n",
    "# objective function\n",
    "def objective(x, y):\n",
    "    \"\"\"\n",
    "    Returns the value of the objective function at the given input point (x, y).\n",
    "    \n",
    "    Parameters:\n",
    "    x (float): The x-coordinate of the input point.\n",
    "    y (float): The y-coordinate of the input point.\n",
    "    \n",
    "    Returns:\n",
    "    float: The value of the objective function at the input point.\n",
    "    \"\"\"\n",
    "    return x**2.0 + y**2.0\n",
    " \n",
    "# derivative of objective function\n",
    "def derivative(x, y):\n",
    "    \"\"\"\n",
    "    Returns the gradient of the objective function at the given input point (x, y).\n",
    "    \n",
    "    Parameters:\n",
    "    x (float): The x-coordinate of the input point.\n",
    "    y (float): The y-coordinate of the input point.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The gradient of the objective function at the input point, as a 2-element NumPy array.\n",
    "    \"\"\"\n",
    "    return asarray([x * 2.0, y * 2.0])\n",
    " \n",
    "# gradient descent algorithm with rmsprop\n",
    "def rmsprop(objective, derivative, bounds, n_iter, step_size, rho):\n",
    "    \"\"\"\n",
    "    Performs the gradient descent optimization algorithm with RMSprop.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    objective : function\n",
    "        The objective function to be optimized.\n",
    "    derivative : function\n",
    "        The derivative of the objective function.\n",
    "    bounds : array-like\n",
    "        The lower and upper bounds for each input variable.\n",
    "    n_iter : int\n",
    "        The maximum number of iterations to perform the optimization algorithm.\n",
    "    step_size : float\n",
    "        The step size for each iteration of the algorithm.\n",
    "    rho : float\n",
    "        The forgetting factor for the moving average of the squared gradient.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    solutions : list of arrays\n",
    "        The sequence of candidate solutions generated by the optimization algorithm.\n",
    "    \"\"\"\n",
    " # track all solutions\n",
    "    solutions = list()\n",
    "     # generate an initial point\n",
    "    x = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "    score = objective(x[0], x[1])\n",
    " # list of the average square gradients for each variable\n",
    "    sq_grad_avg = [0.0 for _ in range(bounds.shape[0])]\n",
    " # run the gradient descent\n",
    "    for it in range(n_iter):\n",
    " # calculate gradient\n",
    "        gradient = derivative(x[0], x[1])\n",
    " # update the average of the squared partial derivatives\n",
    "        for j in range(gradient.shape[0]):\n",
    " # calculate the squared gradient\n",
    "            sg = gradient[j]**2.0\n",
    " # update the moving average of the squared gradient\n",
    "            sq_grad_avg[j] = (sq_grad_avg[j] * rho) + (sg * (1.0-rho))# build solution\n",
    "            new_solution = list()\n",
    "            for i in range(x.shape[0]):# calculate the learning rate for this variable\n",
    "                alpha = step_size / (1e-8 + sqrt(sq_grad_avg[j]))\n",
    " # calculate the new position in this variable\n",
    "                value = x[i] - alpha * gradient[j]\n",
    "                new_solution.append(value)# store the new solution\n",
    "                solution = asarray(new_solution)\n",
    "        solutions.append(solution)\n",
    " # evaluate candidate point\n",
    "        solution_eval = objective(solution[0], solution[1])# report progress\n",
    "        print('>%d f(%s) = %.5f' % (it, solution, solution_eval))\n",
    "    return solutions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b278318b",
   "metadata": {},
   "source": [
    "This code performs a gradient descent search with RMSprop optimization to minimize an objective function defined by the objective function and its derivative function, derivative. The range of input values is defined by the bounds array, and the number of iterations is defined by `n_iter`. The step size for each iteration is defined by `step_size`, and the momentum for RMSprop is defined by `rho`.\n",
    "\n",
    "The code then generates a uniform sample of points within the input range and computes the corresponding target values for the objective function. It creates a filled contour plot of the target values using a color scheme called \"jet\" with 50 levels. The sample points that were generated during the optimization process are plotted as white circles on the contour plot.\n",
    "\n",
    "Finally, the plot is displayed using `pyplot.show()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7d6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed the pseudo random number generator\n",
    "seed(1)\n",
    "# define range for input\n",
    "bounds = asarray([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "# define the total iterations\n",
    "n_iter = 50\n",
    "# define the step size\n",
    "step_size = 0.01\n",
    "# momentum for rmsprop\n",
    "rho = 0.99\n",
    "# perform the gradient descent search with rmsprop\n",
    "solutions = rmsprop(objective, derivative, bounds, n_iter, step_size, rho)\n",
    "# sample input range uniformly at 0.1 increments\n",
    "xaxis = arange(bounds[0,0], bounds[0,1], 0.1)\n",
    "yaxis = arange(bounds[1,0], bounds[1,1], 0.1)\n",
    "# create a mesh from the axis\n",
    "x, y = meshgrid(xaxis, yaxis)\n",
    "# compute targets\n",
    "results = objective(x, y)\n",
    "# create a filled contour plot with 50 levels and jet color scheme\n",
    "pyplot.contourf(x, y, results, levels=50, cmap='jet')\n",
    "# plot the sample as black circles\n",
    "solutions = asarray(solutions)\n",
    "pyplot.plot(solutions[:, 0], solutions[:, 1], '.-', color='w')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8f0df28",
   "metadata": {},
   "source": [
    "# 5. Gradient Descent Algorithm with Adamax Optimization\n",
    "In this code, we're implementing the Adamax optimization algorithm for gradient descent. This algorithm is similar to Adam but replaces the second moment with the weighted infinity norm to better adapt the learning rate based on the magnitude of the gradients.\n",
    "\n",
    "The `objective` function being minimized is defined by the `objective()` function, which takes in two variables x and y and returns their squared sum.\n",
    "\n",
    "The `derivative` function calculates the gradient of the `objective` function at any given point x and y, and returns a 2D array of the partial derivatives with respect to x and y.\n",
    "\n",
    "To start, the algorithm generates an initial point randomly within the bounds defined by the bounds parameter. The `n_iter` parameter specifies the number of iterations the algorithm will run for. The `alpha`, `beta1`, and `beta2` parameters are hyperparameters that control the step size, first and second moment decay rates.\n",
    "\n",
    "During each iteration, the gradient `g` is calculated using the `derivative()` function. The first moment m and weighted infinity norm u are then updated using the current gradient and the hyperparameters. The updated moment and norm are used to calculate a \"momentum-corrected\" estimate of the gradient delta, which is then used to update the point x along the gradient direction. The process repeats until the specified number of iterations is reached.\n",
    "\n",
    "The solutions list stores the updated points x and their corresponding scores, which are printed out during each iteration to track the progress of the algorithm. The final list of solutions is returned at the end of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of plotting the adamax search on a contour plot of the test function\n",
    "# objective function\n",
    "def objective(x, y):\n",
    "\t\"\"\"\n",
    "\tComputes the value of the objective function at a given point (x, y).\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tx : float\n",
    "\t\tThe x-coordinate of the point.\n",
    "\ty : float\n",
    "\t\tThe y-coordinate of the point.\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tfloat\n",
    "\t\tThe value of the objective function at the given point.\n",
    "\t\"\"\"\n",
    "\treturn x**2.0 + y**2.0\n",
    "\n",
    "# derivative of objective function\n",
    "def derivative(x, y):\n",
    "\t\"\"\"\n",
    "\tComputes the partial derivatives of the objective function with respect to its inputs x and y, evaluated at the given values.\n",
    "\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\tx : float\n",
    "\t\tThe value of the input x at which to evaluate the partial derivative.\n",
    "\ty : float\n",
    "\t\tThe value of the input y at which to evaluate the partial derivative.\n",
    "\n",
    "\tReturns:\n",
    "\t--------\n",
    "\tdx : float\n",
    "\t\tThe value of the partial derivative with respect to x at the given point (x,y).\n",
    "\tdy : float\n",
    "\t\tThe value of the partial derivative with respect to y at the given point (x,y).\n",
    "\t\"\"\"\n",
    "\treturn asarray([x * 2.0, y * 2.0])\n",
    "\n",
    "# gradient descent algorithm with adamax\n",
    "def adamax(objective, derivative, bounds, n_iter, alpha, beta1, beta2):\n",
    "\t\"\"\"\n",
    "\tOptimize a function using the Adamax algorithm.\n",
    "\n",
    "\tParameters:\n",
    "\t-----------\n",
    "\tobjective: callable function\n",
    "\t\tObjective function to optimize.\n",
    "\tderivative: callable function\n",
    "\t\tFunction that returns the derivative of the objective function.\n",
    "\tbounds: array-like\n",
    "\t\tBoundaries for the input variables of the objective function.\n",
    "\t\tIt should be an array of shape (n_vars, 2), where n_vars is the number of input variables.\n",
    "\t\tThe i-th element of the array should be an array-like object with 2 elements:\n",
    "\t\tthe lower and upper bound for the i-th variable.\n",
    "\tn_iter: int\n",
    "\t\tNumber of iterations to run the optimization algorithm.\n",
    "\talpha: float\n",
    "\t\tLearning rate or step size parameter.\n",
    "\tbeta1: float\n",
    "\t\tExponential decay rate for the first moment estimates.\n",
    "\tbeta2: float\n",
    "\t\tExponential decay rate for the weighted infinity norm estimates.\n",
    "\n",
    "\tReturns:\n",
    "\t--------\n",
    "\tsolutions: list of arrays\n",
    "\t\tThe solution found at each iteration of the algorithm.\n",
    "\t\"\"\"\n",
    "\tsolutions = list()\n",
    "\t# generate an initial point\n",
    "\tx = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "\t# initialize moment vector and weighted infinity norm\n",
    "\tm = [0.0 for _ in range(bounds.shape[0])]\n",
    "\tu = [0.0 for _ in range(bounds.shape[0])]\n",
    "\t# run iterations of gradient descent\n",
    "\tfor t in range(n_iter):\n",
    "\t\t# calculate gradient g(t)\n",
    "\t\tg = derivative(x[0], x[1])\n",
    "\t\t# build a solution one variable at a time\n",
    "\t\tfor i in range(x.shape[0]):\n",
    "\t\t\t# m(t) = beta1 * m(t-1) + (1 - beta1) * g(t)\n",
    "\t\t\tm[i] = beta1 * m[i] + (1.0 - beta1) * g[i]\n",
    "\t\t\t# u(t) = max(beta2 * u(t-1), abs(g(t)))\n",
    "\t\t\tu[i] = max(beta2 * u[i], abs(g[i]))\n",
    "\t\t\t# step_size(t) = alpha / (1 - beta1(t))\n",
    "\t\t\tstep_size = alpha / (1.0 - beta1**(t+1))\n",
    "\t\t\t# delta(t) = m(t) / u(t)\n",
    "\t\t\tdelta = m[i] / u[i]\n",
    "\t\t\t# x(t) = x(t-1) - step_size(t) * delta(t)\n",
    "\t\t\tx[i] = x[i] - step_size * delta\n",
    "\t\t# evaluate candidate point\n",
    "\t\tscore = objective(x[0], x[1])\n",
    "\t\tsolutions.append(x.copy())\n",
    "\t\t# report progress\n",
    "\t\tprint('>%d f(%s) = %.5f' % (t, x, score))\n",
    "\treturn solutions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecc1a219",
   "metadata": {},
   "source": [
    "This code section performs a gradient descent search with Adamax optimization algorithm for a given objective function and its derivative. The input range is defined by a set of bounds, and the search is performed for a total of 60 iterations with a step size of 0.02. The factors for the average gradient and average squared gradient are set to 0.8 and 0.99, respectively.\n",
    "\n",
    "A contour plot of the objective function is created using the contourf function from the pyplot module of the matplotlib library. The input range is sampled uniformly at 0.1 increments, and a mesh is created from the resulting axis. The filled contour plot has 50 levels and uses the 'jet' color scheme.\n",
    "\n",
    "The resulting solutions of the gradient descent search are plotted as black circles on the contour plot using the plot function from pyplot. The plot is displayed using the show function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de952b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed the pseudo random number generator\n",
    "seed(1)\n",
    "# define range for input\n",
    "bounds = asarray([[-1.0, 1.0], [-1.0, 1.0]])\n",
    "# define the total iterations\n",
    "n_iter = 60\n",
    "# steps size\n",
    "alpha = 0.02\n",
    "# factor for average gradient\n",
    "beta1 = 0.8\n",
    "# factor for average squared gradient\n",
    "beta2 = 0.99\n",
    "# perform the gradient descent search with adamax\n",
    "solutions = adamax(objective, derivative, bounds, n_iter, alpha, beta1, beta2)\n",
    "# sample input range uniformly at 0.1 increments\n",
    "xaxis = arange(bounds[0,0], bounds[0,1], 0.1)\n",
    "yaxis = arange(bounds[1,0], bounds[1,1], 0.1)\n",
    "# create a mesh from the axis\n",
    "x, y = meshgrid(xaxis, yaxis)\n",
    "# compute targets\n",
    "results = objective(x, y)\n",
    "# create a filled contour plot with 50 levels and jet color scheme\n",
    "pyplot.contourf(x, y, results, levels=50, cmap='jet')\n",
    "# plot the sample as black circles\n",
    "solutions = asarray(solutions)\n",
    "pyplot.plot(solutions[:, 0], solutions[:, 1], '.-', color='w')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
