{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<div align=\"center\"><a href=\"https://colab.research.google.com/github/deepkapha/EarthScanWebinar/blob/main/notebook/W2W_dataset_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys \n",
        "sys.path.append('..')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Import the necessaary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHFWu2TegN-c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import gdown\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import matplotlib.colors as mcolors\n",
        "# from PIL import Image\n",
        "from os.path import join as pjoin\n",
        "from utils.well_log_plots import log_plots\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from utils import preprocessing, plot_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', 500)\n",
        "overlap = {name for name in mcolors.CSS4_COLORS\n",
        "           if f'xkcd:{name}' in mcolors.XKCD_COLORS}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Download the dataset from publicly avalialable google drive link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_url = 'https://drive.google.com/file/d/1TkRT5TeX7slPDL20OqYqFLhGX5iK4RHc/view?usp=share_link'\n",
        "test_data_url = 'https://drive.google.com/file/d/1ooDiCKweUrduyy0Q1P7KIXnl04BQqH0_/view?usp=share_link'\n",
        "\n",
        "data_root = '../raw_data'\n",
        "os.makedirs(data_root, exist_ok = True)\n",
        "train_path = pjoin(data_root, \"train.csv\")\n",
        "test_path = pjoin(data_root, \"test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.isfile(train_path):\n",
        "    gdown.download(url=train_data_url, output=train_path, quiet=False, fuzzy=True)\n",
        "\n",
        "if not os.path.isfile(train_path):\n",
        "    gdown.download(url=test_data_url, output=test_path, quiet=False, fuzzy=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_well=30\n",
        "end_well=98"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJq5o7NUlN-I"
      },
      "outputs": [],
      "source": [
        "well_train = preprocessing.load_data(train_path)\n",
        "well_test = preprocessing.load_data(test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPj3VInilSFT"
      },
      "outputs": [],
      "source": [
        "print(\"Shape of Well data:\\n\\tTraining Well: {}\\n\\tTesting Well: {}\".format(well_train.shape, well_test.shape))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r67Jetsmmlm5"
      },
      "source": [
        "# Description of dataset\n",
        "\n",
        "The provided dataset contains well logs, interpreted lithofacies and lithostratigraphy for 90+ released wells from offshore Norway. The well logs include the well name (WELL), the measured depth, x,y,z location for the wireline measurement as well as the well logs CALI, RDEP, RHOB, DHRO, SGR,  GR, RMED, RMIC, NPHI, PEF, RSHA, DTC, SP, BS, ROP, DTS, DCAL, MUDWEIGHT. An explanation of the abbreviations is shown in the figure below. \n",
        "\n",
        "<center>\n",
        "<img src=\"../asset/well_log_abbreviations.png\">\n",
        "</center>\n",
        "\n",
        "Click [here](https://drive.google.com/drive/folders/1GIkjq4fwgwbiqVQxYwoJnOJWVobZ91pL) to check the results."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WNAXI5IQ2MJQ"
      },
      "source": [
        "Given below is the Statistical description of the few important logs from the raw_data\n",
        "\n",
        "\n",
        "| Log Name | min_scale | max_scale | description |\n",
        "|----------|-----------|-----------|-------------|\n",
        "| CALI     |  6        |   24      |             |\n",
        "| GR       |  0        |   150     |             |\n",
        "| SP       |  -150     |   150     |             |\n",
        "| SGR      |  0        |   150     |             |\n",
        "| RSHA     |  0.2      |   200     |             |\n",
        "| RMED     |  0.2      |   200     |             |\n",
        "| RDEP     |  0.2      |   200     |             |\n",
        "| RMIC     |  0.2      | 200 ohm-m |             |\n",
        "| RXO      |  0.2      | 200 ohm-m |             |                 \n",
        "| ROPA     |   0       |    50     |             |\n",
        "| ROP      |   0       |    50     |             |\n",
        "| DTC      |   40       |  240      |             |\n",
        "| DTS      |   40       |  240      |             |\n",
        "| NPHI     |   0.05    |  -0.15    |             |\n",
        "| RHOB     |   0.95    |   2.95    |             |\n",
        "| PEF      |  0        |10 barns/electron|       |             \n",
        "| DCAL     |  6        |    24     |             |\n",
        "| DRHO     |  -0.2     |   1       |             |\n",
        "|MUDWEIGHT |    0       |  150         |             |\n",
        "|BS        |     6      |    24       |             |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNL_xJq-lVx9"
      },
      "outputs": [],
      "source": [
        "total_training_wells = preprocessing.count_well(well_train)\n",
        "total_testing_wells = preprocessing.count_well(well_test)\n",
        "\n",
        "print('Total number of wells present in the dataset:\\n\\tTraining Well: {}\\n\\tTesting Well: {}'.format(total_training_wells, total_testing_wells))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK-UrKMDpFzP"
      },
      "outputs": [],
      "source": [
        "print(f\"Unique wells present in the dataset are:\\n\\t{well_train.WELL.unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d87ILMdxl8hp"
      },
      "outputs": [],
      "source": [
        "well_train_names = preprocessing.get_well_names(well_train)\n",
        "well_test_names = preprocessing.get_well_names(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwnIH-wmv8Fn"
      },
      "outputs": [],
      "source": [
        "overlapped_well_count, overlapped_well_name = preprocessing.get_overlapping_well(well_train, well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKuT_3QFmAl-"
      },
      "outputs": [],
      "source": [
        "well_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKM5hYh12MJT"
      },
      "outputs": [],
      "source": [
        "print(\"Max mud weight value is\",np.max(well_train[\"MUDWEIGHT\"]))\n",
        "print(\"Max mud weight value is\",np.min(well_train[\"MUDWEIGHT\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFZgbjF7xNEz"
      },
      "outputs": [],
      "source": [
        "well_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8VxerljmO5B"
      },
      "outputs": [],
      "source": [
        "preprocessing.get_random_well(well_train, 2020).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hH-PBkWu5d0"
      },
      "outputs": [],
      "source": [
        "percet_missing_train_data = preprocessing.percet_missing_data(well_train)\n",
        "percet_missing_test_data = preprocessing.percet_missing_data(well_test)\n",
        "\n",
        "_, ax = plt.subplots(1, 2, figsize = (20, 4))\n",
        "percet_missing_train_data.plot(kind='bar', ax=ax[0])\n",
        "percet_missing_test_data.plot(kind='bar', ax=ax[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h9yD7nqkt0s"
      },
      "outputs": [],
      "source": [
        "#preprocessing.remove_column_with_half_of_nan_value(well_train)\n",
        "#preprocessing.remove_column_with_half_of_nan_value(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnzKeYdP0SD4"
      },
      "outputs": [],
      "source": [
        "training_group_names = preprocessing.group_identification(well_train)\n",
        "print()\n",
        "testing_group_names = preprocessing.group_identification(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn_0h2e54nM3"
      },
      "outputs": [],
      "source": [
        "nonoverlapped_groups_count, nonoverlapped_groups_name = preprocessing.get_nonoverlapping_groups(training_group_names, testing_group_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EssAvRV5rsCH"
      },
      "outputs": [],
      "source": [
        "preprocessing.missing_group_info(well_train)\n",
        "preprocessing.missing_group_info(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjKfHY7aC3j-"
      },
      "outputs": [],
      "source": [
        "preprocessing.remove_formation_column(well_train)\n",
        "preprocessing.remove_formation_column(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_D1iLPBC3bO"
      },
      "outputs": [],
      "source": [
        "well_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAVzynKSDA7M"
      },
      "outputs": [],
      "source": [
        "well_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nFHzXP81VWi"
      },
      "outputs": [],
      "source": [
        "preprocessing.get_random_well(well_train, 2023).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBqUx1aU2MJW"
      },
      "outputs": [],
      "source": [
        "# undeviated_wells = preprocessing.get_undeviated_well_info(well_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGd8Ln872MJW"
      },
      "outputs": [],
      "source": [
        "rand_well = preprocessing.get_random_well(well_train)\n",
        "plot_utils.plot2Dlocation(rand_well)\n",
        "plot_utils.plot3Dlocation(rand_well)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLp3pI9Y2ar7"
      },
      "outputs": [],
      "source": [
        "well_train_with_missing_group_info = preprocessing.get_well_with_no_group_info(well_train, total_training_wells, well_train_names)\n",
        "well_test_with_missing_group_info = preprocessing.get_well_with_no_group_info(well_test, total_testing_wells, well_test_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiOIUKIm8TmD"
      },
      "outputs": [],
      "source": [
        "well_train.GROUP.loc[well_train[well_train['WELL'] == well_train_with_missing_group_info[0]].GROUP.index] = preprocessing.fill_group_na_value(well_train, well_train_with_missing_group_info[0])\n",
        "well_train.GROUP.loc[well_train[well_train['WELL'] == well_train_with_missing_group_info[1]].GROUP.index] = preprocessing.fill_group_na_value(well_train, well_train_with_missing_group_info[1])\n",
        "well_train.GROUP.loc[well_train[well_train['WELL'] == well_train_with_missing_group_info[2]].GROUP.index] = preprocessing.fill_group_na_value(well_train, well_train_with_missing_group_info[2])\n",
        "well_train.GROUP.loc[well_train[well_train['WELL'] == well_train_with_missing_group_info[3]].GROUP.index] = preprocessing.fill_group_na_value(well_train, well_train_with_missing_group_info[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_lpRM_AHoDX"
      },
      "outputs": [],
      "source": [
        "preprocessing.percet_missing_data(well_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhQ95dMR2MJX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyeysdRY2MJX"
      },
      "outputs": [],
      "source": [
        "log_plot(well_train[well_train['WELL'] == '15/9-13'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewJxmO1o2MJX"
      },
      "outputs": [],
      "source": [
        "def log_plot_image(logs,plotname,txtname,i,patch_height):\n",
        "    _, ax = plt.subplots(1,19, figsize = (20, 10), sharey = True, gridspec_kw = {'wspace':0, 'hspace':0})\n",
        "    ax[0].invert_yaxis()\n",
        "    ax[1].invert_yaxis()\n",
        "    ax[2].invert_yaxis()\n",
        "    ax[3].invert_yaxis()\n",
        "    ax[4].invert_yaxis()\n",
        "    ax[5].invert_yaxis()\n",
        "    ax[6].invert_yaxis()\n",
        "    ax[7].invert_yaxis()\n",
        "    ax[8].invert_yaxis()\n",
        "    ax[9].invert_yaxis()\n",
        "    ax[10].invert_yaxis()\n",
        "    ax[11].invert_yaxis()\n",
        "    ax[12].invert_yaxis()\n",
        "    ax[13].invert_yaxis()\n",
        "    ax[14].invert_yaxis()\n",
        "    ax[15].invert_yaxis()\n",
        "    ax[16].invert_yaxis()\n",
        "    ax[17].invert_yaxis()\n",
        "    ax[18].invert_yaxis()\n",
        "\n",
        "\n",
        "    ax[0].plot(logs.CALI[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[0].set_xlim(6, 24)\n",
        "    ax[0].axis('off')\n",
        "    ax[1].plot(logs.GR[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[1].set_xlim(0, 150)\n",
        "    ax[1].axis('off')\n",
        "    ax[2].plot(logs.SP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[2].set_xlim(-150, 150)\n",
        "    ax[2].axis('off')\n",
        "    ax[3].plot(logs.SGR[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[3].set_xlim(0, 150)\n",
        "    ax[3].axis('off')\n",
        "    ax[4].semilogx(logs.RSHA[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[4].set_xlim(2, 200)\n",
        "    ax[4].axis('off')\n",
        "    ax[5].semilogx(logs.RMED[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[5].set_xlim(2, 200)\n",
        "    ax[5].axis('off')\n",
        "    ax[6].semilogx(logs.RDEP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[6].set_xlim(2, 200)\n",
        "    ax[6].axis('off')\n",
        "    ax[7].semilogx(logs.RXO[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[7].set_xlim(2, 200)\n",
        "    ax[7].axis('off')\n",
        "    ax[8].semilogx(logs.RMIC[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[8].set_xlim(2, 200)\n",
        "    ax[8].axis('off')\n",
        "    ax[9].plot(logs.NPHI[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[9].set_xlim(-0.15, 1.05)\n",
        "    ax[9].invert_xaxis()\n",
        "    ax[9].axis('off')\n",
        "    ax[10].plot(logs.RHOB[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[10].set_xlim(0.95, 2.95)\n",
        "    ax[10].invert_xaxis()\n",
        "    ax[10].axis('off')\n",
        "    ax[11].plot(logs.PEF[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[11].set_xlim(0, 10)\n",
        "    ax[11].axis('off')\n",
        "    ax[12].plot(logs.ROP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[12].set_xlim(0, 50)\n",
        "    ax[12].axis('off')\n",
        "    ax[13].plot(logs.ROPA[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[13].set_xlim(0, 50)\n",
        "    ax[13].axis('off')\n",
        "    ax[14].plot(logs.DRHO[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[14].set_xlim(-0.2, 1)\n",
        "    ax[14].axis('off')\n",
        "    ax[15].plot(logs.DTC[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[15].set_xlim(40, 240)\n",
        "    ax[15].invert_xaxis()\n",
        "    ax[15].axis('off')\n",
        "    ax[16].plot(logs.DTS[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[16].set_xlim(40, 240)\n",
        "    ax[16].invert_xaxis()\n",
        "    ax[16].axis('off')\n",
        "    ax[17].plot(logs.MUDWEIGHT[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[17].set_xlim(0, 150)\n",
        "    ax[17].axis('off')\n",
        "    ax[18].plot(logs.BS[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[18].set_xlim(6, 24)\n",
        "    ax[18].axis('off')\n",
        "    \n",
        "     \n",
        "    plt.savefig(plotname,bbox_inches =\"tight\",transparent = False)\n",
        "    #im = Image.open(plotname)\n",
        "    #newsize = (800, 360)\n",
        "    #im = im.resize(newsize)\n",
        "    #im =im.save(plotname)\n",
        "\n",
        "    with open(txtname, 'w', encoding='UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "    # write a row to the csv file\n",
        "        writer.writerow(logs.GROUP[i:i+patch_height][:-1].T)\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bny_YLyi2MJX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def randon_list_generator():\n",
        "    randomlist = []\n",
        "    for i in range(0,50):\n",
        "        n = random.randint(0,18)\n",
        "        if n not in randomlist:\n",
        "            randomlist.append(n)\n",
        "    if len(randomlist) == 19: \n",
        "        return randomlist\n",
        "    else:\n",
        "        return randon_list_generator()\n",
        "    \n",
        "\n",
        "randomlist = randon_list_generator()\n",
        "print(randomlist)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lP7VXPz2MJX"
      },
      "outputs": [],
      "source": [
        "def log_plot_image_random(logs,plotname,txtname,i,patch_height,randomlist):\n",
        "    _, ax = plt.subplots(1,19, figsize = (20, 10), sharey = True, gridspec_kw = {'wspace':0, 'hspace':0})\n",
        "    j=0\n",
        "    for i in randomlist:\n",
        "        op= log_plots[i]\n",
        "        op(well_train[well_train['WELL'] == well_train_names[0]],ax[j],0,700)\n",
        "        j=j+1\n",
        "    plt.savefig(plotname,bbox_inches =\"tight\",transparent = False)\n",
        "    #im = Image.open(plotname)\n",
        "    #newsize = (800, 360)\n",
        "    #im = im.resize(newsize)\n",
        "    #im =im.save(plotname)\n",
        "\n",
        "    with open(txtname, 'w', encoding='UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        # write a row to the csv file\n",
        "        writer.writerow(logs.GROUP[i:i+patch_height])\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klToEKR52MJY"
      },
      "outputs": [],
      "source": [
        "def log_plot_image_invert(logs,plotname,txtname,i,patch_height):\n",
        "    _, ax = plt.subplots(1,19, figsize = (20, 10), sharey = True, gridspec_kw = {'wspace':0, 'hspace':0})\n",
        "\n",
        "\n",
        "\n",
        "    ax[0].plot(logs.CALI[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[0].set_xlim(6, 24)\n",
        "    ax[0].axis('off')\n",
        "    ax[1].plot(logs.GR[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[1].set_xlim(0, 150)\n",
        "    ax[1].axis('off')\n",
        "    ax[2].plot(logs.SP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[2].set_xlim(-150, 150)\n",
        "    ax[2].axis('off')\n",
        "    ax[3].plot(logs.SGR[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[3].set_xlim(0, 150)\n",
        "    ax[3].axis('off')\n",
        "    ax[4].semilogx(logs.RSHA[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[4].set_xlim(2, 200)\n",
        "    ax[4].axis('off')\n",
        "    ax[5].semilogx(logs.RMED[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[5].set_xlim(2, 200)\n",
        "    ax[5].axis('off')\n",
        "    ax[6].semilogx(logs.RDEP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[6].set_xlim(2, 200)\n",
        "    ax[6].axis('off')\n",
        "    ax[7].semilogx(logs.RXO[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[7].set_xlim(2, 200)\n",
        "    ax[7].axis('off')\n",
        "    ax[8].semilogx(logs.RMIC[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[8].set_xlim(2, 200)\n",
        "    ax[8].axis('off')\n",
        "    ax[9].plot(logs.NPHI[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[9].set_xlim(-0.15, 1.05)\n",
        "    ax[9].invert_xaxis()\n",
        "    ax[9].axis('off')\n",
        "    ax[10].plot(logs.RHOB[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[10].set_xlim(0.95, 2.95)\n",
        "    ax[10].invert_xaxis()\n",
        "    ax[10].axis('off')\n",
        "    ax[11].plot(logs.PEF[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[11].set_xlim(0, 10)\n",
        "    ax[11].axis('off')\n",
        "    ax[12].plot(logs.ROP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[12].set_xlim(0, 50)\n",
        "    ax[12].axis('off')\n",
        "    ax[13].plot(logs.ROPA[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[13].set_xlim(0, 50)\n",
        "    ax[13].axis('off')\n",
        "    ax[14].plot(logs.DRHO[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[14].set_xlim(-0.2, 1)\n",
        "    ax[14].axis('off')\n",
        "    ax[15].plot(logs.DTC[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[15].set_xlim(40, 240)\n",
        "    ax[15].invert_xaxis()\n",
        "    ax[15].axis('off')\n",
        "    ax[16].plot(logs.DTS[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[16].set_xlim(40, 240)\n",
        "    ax[16].invert_xaxis()\n",
        "    ax[16].axis('off')\n",
        "    ax[17].plot(logs.MUDWEIGHT[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[17].set_xlim(0, 150)\n",
        "    ax[17].axis('off')\n",
        "    ax[18].plot(logs.BS[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[18].set_xlim(6, 24)\n",
        "    ax[18].axis('off')\n",
        "    \n",
        "     \n",
        "    plt.savefig(plotname,bbox_inches =\"tight\",transparent = False)\n",
        "    #im = Image.open(plotname)\n",
        "    #newsize = (800, 360)\n",
        "    #im = im.resize(newsize)\n",
        "    #im =im.save(plotname)\n",
        "\n",
        "    with open(txtname, 'w', encoding='UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "    # write a row to the csv file\n",
        "        writer.writerow(logs.GROUP[i:i+patch_height])\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMxrJCQR2MJY"
      },
      "outputs": [],
      "source": [
        "count =0\n",
        "for j in range(start_well,end_well,1):\n",
        "        well_shape = len(well_train[well_train['WELL'] == well_train_names[j]])\n",
        "        \n",
        "        for i in tqdm(range(0, well_shape, 350)):\n",
        "                plotname = \"well-images/well_\"+str(j)+\"_\"+str(i)+\".jpg\"\n",
        "                txtname = \"well-images/well_\"+str(j)+\"_\"+str(i)+\".csv\"\n",
        "                \n",
        "                if i+700 > well_shape:\n",
        "                        well_not700 = well_shape-i\n",
        "                        #print(i, well_not700+i ,i-(700-well_not700), i-(700-well_not700)+700)\n",
        "                        log_plot_image(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i-(700-well_not700),700)\n",
        "                else:\n",
        "                        log_plot_image(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i,700)\n",
        "                \n",
        "                \n",
        "                        \n",
        "                count = count+1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjZDRiJe2MJY"
      },
      "outputs": [],
      "source": [
        "count =0\n",
        "for j in range(start_well,end_well,1):\n",
        "        well_shape = len(well_train[well_train['WELL'] == well_train_names[j]])\n",
        "        \n",
        "        for i in tqdm(range(0, well_shape, 350)):\n",
        "                plotname = \"well-images/random_well_\"+str(j)+\"_\"+str(i)+\".jpg\"\n",
        "                txtname = \"well-images/random_well_\"+str(j)+\"_\"+str(i)+\".csv\"\n",
        "                randomlist = randon_list_generator()\n",
        "                if i+700 > well_shape:\n",
        "                        well_not700 = well_shape-i\n",
        "                        #print(i, well_not700+i ,i-(700-well_not700), i-(700-well_not700)+700)\n",
        "                        log_plot_image_random(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i-(700-well_not700),700, randomlist)\n",
        "                else:\n",
        "                        log_plot_image_random(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i,700, randomlist)\n",
        "                \n",
        "                \n",
        "                        \n",
        "                count = count+1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McrHyY0q2MJY"
      },
      "outputs": [],
      "source": [
        "count =0\n",
        "for j in range(start_well,end_well,1):\n",
        "        well_shape = len(well_train[well_train['WELL'] == well_train_names[j]])\n",
        "        \n",
        "        for i in tqdm(range(0, well_shape, 350)):\n",
        "                plotname = \"well-images/invert_well_\"+str(j)+\"_\"+str(i)+\".jpg\"\n",
        "                txtname = \"well-images/invert_well_\"+str(j)+\"_\"+str(i)+\".csv\"\n",
        "                \n",
        "                if i+700 > well_shape:\n",
        "                        well_not700 = well_shape-i\n",
        "                        #print(i, well_not700+i ,i-(700-well_not700), i-(700-well_not700)+700)\n",
        "                        log_plot_image_invert(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i-(700-well_not700),700)\n",
        "                else:\n",
        "                        log_plot_image_invert(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i,700)\n",
        "                \n",
        "                \n",
        "                        \n",
        "                count = count+1\n",
        "print(count)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "WellLogCorrelation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "76516d6b897135ed65d745bd4f515773909c9fa8a0be9c41200fccb5833e624b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
