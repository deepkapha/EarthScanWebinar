{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepkapha/EarthScanWebinar/blob/main/notebook/W2W_dataset_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHFWu2TegN-c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 500)\n",
        "import numpy as np\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from tqdm import tqdm\n",
        "import matplotlib.colors as mcolors\n",
        "from PIL import Image\n",
        "from composer.algorithms.augmix import AugmentAndMixTransform\n",
        "\n",
        "overlap = {name for name in mcolors.CSS4_COLORS\n",
        "           if f'xkcd:{name}' in mcolors.XKCD_COLORS}\n",
        "from well_log_plots import log_plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwAMItPM2MJO"
      },
      "outputs": [],
      "source": [
        "start_well=30\n",
        "end_well=98\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJq5o7NUlN-I"
      },
      "outputs": [],
      "source": [
        "def load_data(path, delimiter = ';'):\n",
        "    return pd.read_csv(path, delimiter = delimiter)\n",
        "\n",
        "well_train = load_data('/home/deepkapha/W2W/StratigraphicWellLogCorrelation/raw_data/train.csv')\n",
        "well_test = load_data('/home/deepkapha/W2W/StratigraphicWellLogCorrelation/raw_data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPj3VInilSFT"
      },
      "outputs": [],
      "source": [
        "print(\"Shape of Well data:\\n\\tTraining Well: {}\\n\\tTesting Well: {}\".format(well_train.shape, well_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r67Jetsmmlm5"
      },
      "source": [
        "# Description of dataset\n",
        "\n",
        "The provided dataset contains well logs, interpreted lithofacies and lithostratigraphy for 90+ released wells from offshore Norway. The well logs include the well name (WELL), the measured depth, x,y,z location for the wireline measurement as well as the well logs CALI, RDEP, RHOB, DHRO, SGR,  GR, RMED, RMIC, NPHI, PEF, RSHA, DTC, SP, BS, ROP, DTS, DCAL, MUDWEIGHT. An explanation of the abbreviations is shown in the figure below. \n",
        "\n",
        "<center>\n",
        "<img src=\"https://images.ctfassets.net/yr01c1s2xcnk/6XiofgUd13JFClPg9tRyRM/cd36b07b81942530af33269d6eff8952/well_log_abbreviations.png\">\n",
        "</center> \n",
        "check results https://drive.google.com/drive/folders/1GIkjq4fwgwbiqVQxYwoJnOJWVobZ91pL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNAXI5IQ2MJQ"
      },
      "source": [
        "| Log Name | min_scale | max_scale | description |\n",
        "|----------|-----------|-----------|-------------|\n",
        "| CALI     |  6        |   24      |             |\n",
        "| GR       |  0        |   150     |             |\n",
        "| SP       |  -150     |   150     |             |\n",
        "| SGR      |  0        |   150     |             |\n",
        "| RSHA     |  0.2      |   200     |             |\n",
        "| RMED     |  0.2      |   200     |             |\n",
        "| RDEP     |  0.2      |   200     |             |\n",
        "| RMIC     |  0.2      | 200 ohm-m |             |\n",
        "| RXO      |  0.2      | 200 ohm-m |             |                 \n",
        "| ROPA     |   0       |    50     |             |\n",
        "| ROP      |   0       |    50     |             |\n",
        "| DTC      |   40       |  240      |             |\n",
        "| DTS      |   40       |  240      |             |\n",
        "| NPHI     |   0.05    |  -0.15    |             |\n",
        "| RHOB     |   0.95    |   2.95    |             |\n",
        "| PEF      |  0        |10 barns/electron|       |             \n",
        "| DCAL     |  6        |    24     |             |\n",
        "| DRHO     |  -0.2     |   1       |             |\n",
        "|MUDWEIGHT |    0       |  150         |             |\n",
        "|BS        |     6      |    24       |             |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNL_xJq-lVx9"
      },
      "outputs": [],
      "source": [
        "def count_well(data):\n",
        "    return data.WELL.value_counts().shape[0]\n",
        "\n",
        "total_training_wells = count_well(well_train)\n",
        "total_testing_wells = count_well(well_test)\n",
        "\n",
        "print('Total number of wells present in the dataset:\\n\\tTraining Well: {}\\n\\tTesting Well: {}'.format(total_training_wells, total_testing_wells))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK-UrKMDpFzP"
      },
      "outputs": [],
      "source": [
        "well_train.WELL.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d87ILMdxl8hp"
      },
      "outputs": [],
      "source": [
        "def get_well_names(data):\n",
        "    return list(data.WELL.value_counts().index)\n",
        "\n",
        "well_train_names = get_well_names(well_train)\n",
        "well_test_names = get_well_names(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwnIH-wmv8Fn"
      },
      "outputs": [],
      "source": [
        "def get_overlapping_well(training_data, testing_data):\n",
        "\n",
        "    count_overlapping_well = 0\n",
        "    overlapped_well = []\n",
        "    for well in get_well_names(testing_data):\n",
        "        if well in get_well_names(training_data) == True:\n",
        "            count_overlapping_well+=1\n",
        "            overlapped_well.append(well)\n",
        "        if count_overlapping_well !=0:\n",
        "            print(\"Total numbers of testing wells overlapping in training wells: {} and their names are {}\".format(count_overlapping_well, overlapped_well))\n",
        "            return (count_overlapping_well, overlapped_well)\n",
        "        else:\n",
        "            print(\"Total numbers of testing wells overlapping in training wells: {}\".format(count_overlapping_well))\n",
        "            return (count_overlapping_well, None)\n",
        "\n",
        "overlapped_well_count, overlapped_well_name = get_overlapping_well(well_train, well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKuT_3QFmAl-"
      },
      "outputs": [],
      "source": [
        "well_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKM5hYh12MJT"
      },
      "outputs": [],
      "source": [
        "print(\"Max mud weight value is\",np.max(well_train[\"MUDWEIGHT\"]))\n",
        "print(\"Max mud weight value is\",np.min(well_train[\"MUDWEIGHT\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFZgbjF7xNEz"
      },
      "outputs": [],
      "source": [
        "well_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8VxerljmO5B"
      },
      "outputs": [],
      "source": [
        "def get_random_well(data, seed = None):\n",
        "    \n",
        "    if seed:\n",
        "        np.random.seed(seed)\n",
        "    rand_well_index = np.random.randint(0, count_well(data))\n",
        "    rand_well_name = get_well_names(data)[rand_well_index]\n",
        "    print('Displaying information for Well {}'.format(rand_well_name))\n",
        "    rand_well_data = data[data['WELL'] == rand_well_name]\n",
        "\n",
        "    return rand_well_data\n",
        "\n",
        "get_random_well(well_train, 2020).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wagYY7aBzff"
      },
      "outputs": [],
      "source": [
        "def percet_missing_data(dataframe):\n",
        "    return dataframe.isna().sum()/dataframe.shape[0]*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hH-PBkWu5d0"
      },
      "outputs": [],
      "source": [
        "print('Displaying %age of missing data points for all columns in training data\\n')\n",
        "print(percet_missing_data(well_train))\n",
        "print('\\n' + '='*80 + '\\n\\nDisplaying %age of missing data points for all columns in testing data\\n')\n",
        "print(percet_missing_data(well_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4h9yD7nqkt0s"
      },
      "outputs": [],
      "source": [
        "#def remove_column_with_half_of_nan_value(data):\n",
        "\n",
        "#    print(\"Removing columns which have 50% of missing data i.e., 'SGR', 'ROP', 'DTS', 'DCAL', 'MUDWEIGHT', 'RMIC', 'ROPA', 'RXO', 'BS', 'DRHO'\")\n",
        "#    data.drop(['SGR', 'ROP', 'DTS', 'DCAL', 'MUDWEIGHT', 'RMIC', 'ROPA', 'RXO', 'BS', 'DRHO'], axis = 1, inplace = True)\n",
        "\n",
        "#remove_column_with_half_of_nan_value(well_train)\n",
        "#remove_column_with_half_of_nan_value(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnzKeYdP0SD4"
      },
      "outputs": [],
      "source": [
        "def group_identification(data):\n",
        "\n",
        "    value_counts = data.GROUP.value_counts()\n",
        "    print('Displaying all the GROPUs available in the dataset\\nTotal {} GROUPS found in the dataset'.format(value_counts.count()))\n",
        "    print(value_counts)\n",
        "    return value_counts.index\n",
        "\n",
        "training_group_names = group_identification(well_train)\n",
        "print()\n",
        "testing_group_names = group_identification(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn_0h2e54nM3"
      },
      "outputs": [],
      "source": [
        "def get_nonoverlapping_groups(train_group, test_group):\n",
        "\n",
        "    count_nonoverlapping_groups = 0\n",
        "    nonoverlapped_groups = []\n",
        "    for group in test_group:\n",
        "        if (group in train_group) == False:\n",
        "            count_nonoverlapping_groups+=1\n",
        "            nonoverlapped_groups.append(well)\n",
        "        if count_nonoverlapping_groups !=0:\n",
        "            print(\"Total numbers of GROUPS in testing wells that is not overlapping in training wells: {} and their names are {}\".format(count_nonoverlapping_groups, nonoverlapped_groups))\n",
        "            return (count_nonoverlapping_groups, nonoverlapped_groups)\n",
        "        else:\n",
        "            print(\"Total numbers of GROUPS in testing wells that is not overlapping in training wells: {}\".format(count_nonoverlapping_groups))\n",
        "            return (count_nonoverlapping_groups, None)\n",
        "\n",
        "nonoverlapped_groups_count, nonoverlapped_groups_name = get_nonoverlapping_groups(training_group_names, testing_group_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EssAvRV5rsCH"
      },
      "outputs": [],
      "source": [
        "def missing_group_info(data):\n",
        "    print('Total data points with missing Group information: {}'.format(data.GROUP.isna().sum()))\n",
        "\n",
        "missing_group_info(well_train)\n",
        "missing_group_info(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofTo1SFksd6z"
      },
      "outputs": [],
      "source": [
        "def remove_formation_column(data):\n",
        "\n",
        "    print('Removing FORMATION column from the dataset')\n",
        "    data.drop(['FORMATION'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjKfHY7aC3j-"
      },
      "outputs": [],
      "source": [
        "remove_formation_column(well_train)\n",
        "remove_formation_column(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_D1iLPBC3bO"
      },
      "outputs": [],
      "source": [
        "well_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAVzynKSDA7M"
      },
      "outputs": [],
      "source": [
        "well_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nFHzXP81VWi"
      },
      "outputs": [],
      "source": [
        "get_random_well(well_train, 2020).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpYykkEs2MJV"
      },
      "outputs": [],
      "source": [
        "def get_undeviated_well_info(data):\n",
        "    well_names = []\n",
        "    for well_name in get_well_names(data):\n",
        "        well_data = data[data.WELL == well_name]\n",
        "        if (well_data.X_LOC.value_counts().shape[0] == 1) and (well_data.Y_LOC.value_counts().shape[0] == 1):\n",
        "            well_names.append(well_name)\n",
        "            \n",
        "    print('Total Number of undeviated wells present in the dataset is {} and their names are:\\n{}'.format(len(well_names), \n",
        "                                                                                                          well_names))\n",
        "    return well_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBqUx1aU2MJW"
      },
      "outputs": [],
      "source": [
        "undeviated_wells = get_undeviated_well_info(well_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPmDwbx52MJW"
      },
      "outputs": [],
      "source": [
        "def plot3Dlocation(rand_well):\n",
        "    x_loc = rand_well.X_LOC\n",
        "    y_loc = rand_well.Y_LOC\n",
        "    z_loc = np.abs(rand_well.Z_LOC)\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 12))\n",
        "    ax = plt.axes(projection='3d')\n",
        "    ax.plot3D(x_loc, y_loc, np.abs(z_loc))\n",
        "\n",
        "    ax.plot3D(x_loc.values[0], y_loc.values[0], z_loc.values[0], marker='s', color='black', ms=8)\n",
        "    ax.plot3D(x_loc.values[-1], y_loc.values[-1], z_loc.values[-1], marker='*', color='red', ms=8)\n",
        "    ax.set_xlabel('X Location')\n",
        "    ax.set_ylabel('Y Location')\n",
        "    ax.set_zlabel('TVD')\n",
        "    ax.invert_zaxis()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9QT8W9u2MJW"
      },
      "outputs": [],
      "source": [
        "def plot2Dlocation(rand_well):\n",
        "    x_loc = rand_well.X_LOC\n",
        "    y_loc = rand_well.Y_LOC\n",
        "    z_loc = np.abs(rand_well.Z_LOC)\n",
        "\n",
        "    _, ax = plt.subplots(1, 3, figsize = (20, 5))\n",
        "\n",
        "    ax[0].plot(x_loc, y_loc)\n",
        "    ax[0].set_title('X Location vs Y Location')\n",
        "    ax[0].set_xticks([])\n",
        "    ax[0].set_yticks([])\n",
        "    ax[0].set_xlabel('X')\n",
        "    ax[0].set_ylabel('Y')\n",
        "\n",
        "    ax[1].plot(x_loc, z_loc)\n",
        "    ax[1].set_title('X Location vs TVDss')\n",
        "    ax[1].set_xticks([])\n",
        "    ax[1].set_xlabel('X')\n",
        "    ax[1].set_ylabel('TVDss')\n",
        "    ax[1].plot(x_loc.values[0], z_loc.values[0], marker='s', color='black', ms=8)\n",
        "    ax[1].plot(x_loc.values[-1], z_loc.values[-1], marker='*', color='red', ms=8)\n",
        "    ax[2].invert_yaxis()\n",
        "\n",
        "    ax[2].plot(y_loc, z_loc)\n",
        "    ax[2].set_title('Y Location vs TVDss')\n",
        "    ax[2].set_xticks([])\n",
        "    ax[2].set_xlabel('Y')\n",
        "    ax[2].set_ylabel('TVDss')\n",
        "    ax[2].plot(y_loc.values[0], z_loc.values[0], marker='s', color='black', ms=8)\n",
        "    ax[2].plot(y_loc.values[-1], z_loc.values[-1], marker='*', color='red', ms=8)\n",
        "    ax[2].invert_yaxis()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGd8Ln872MJW"
      },
      "outputs": [],
      "source": [
        "rand_well = get_random_well(well_train)\n",
        "plot2Dlocation(rand_well)\n",
        "plot3Dlocation(rand_well)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLp3pI9Y2ar7"
      },
      "outputs": [],
      "source": [
        "def get_well_with_no_group_info(data, total_num_wells, well_names):\n",
        "\n",
        "    well_with_missing_group_info = []\n",
        "\n",
        "    for well_names_index in range(total_num_wells):\n",
        "        single_well_name = well_names[well_names_index]\n",
        "        single_well_data = data[data['WELL'] == single_well_name]\n",
        "        total_group_data_missing = single_well_data.GROUP.isna().sum()\n",
        "        if total_group_data_missing != 0:\n",
        "            print('Well \"{0}\" is having missing information on GROUP and total data points missing this information is {1}'.format(single_well_name, total_group_data_missing))\n",
        "            well_with_missing_group_info.append(single_well_name)\n",
        "    print('\\nTotal {} Wells have missing group information!'.format(len(well_with_missing_group_info)))\n",
        "    return well_with_missing_group_info\n",
        "\n",
        "well_train_with_missing_group_info = get_well_with_no_group_info(well_train, total_training_wells, well_train_names)\n",
        "well_test_with_missing_group_info = get_well_with_no_group_info(well_test, total_testing_wells, well_test_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR6LzR55GEgW"
      },
      "outputs": [],
      "source": [
        "def fill_group_na_value(data, well_name, method = 'bfill'):\n",
        "    return data[data['WELL'] == well_name].GROUP.fillna(method = method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiOIUKIm8TmD"
      },
      "outputs": [],
      "source": [
        "well_train.GROUP.loc[well_train[well_train['WELL'] == well_train_with_missing_group_info[0]].GROUP.index] = fill_group_na_value(well_train, well_train_with_missing_group_info[0])\n",
        "well_train.GROUP.loc[well_train[well_train['WELL'] == well_train_with_missing_group_info[1]].GROUP.index] = fill_group_na_value(well_train, well_train_with_missing_group_info[1])\n",
        "well_train.GROUP.loc[well_train[well_train['WELL'] == well_train_with_missing_group_info[2]].GROUP.index] = fill_group_na_value(well_train, well_train_with_missing_group_info[2])\n",
        "well_train.GROUP.loc[well_train[well_train['WELL'] == well_train_with_missing_group_info[3]].GROUP.index] = fill_group_na_value(well_train, well_train_with_missing_group_info[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_lpRM_AHoDX"
      },
      "outputs": [],
      "source": [
        "percet_missing_data(well_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhQ95dMR2MJX"
      },
      "outputs": [],
      "source": [
        "def xaxis(ax, xmin, xmax, spines_pos, color, log_name, name_size, y):\n",
        "    ax.set_xticks((xmin, xmax))\n",
        "    ax.spines['top'].set_position(('outward', spines_pos))\n",
        "    ax.spines['top'].set_color(color)\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.xaxis.set_label_position('top')\n",
        "    ax.xaxis.set_label_coords(0.5, y)\n",
        "    ax.set_xlabel(log_name, color = color, size = name_size)\n",
        "    ax.tick_params(axis = 'x', colors = color, size = 0, labelsize = 10)\n",
        "\n",
        "def log_plot(logs):\n",
        "    _, ax = plt.subplots(1,5, figsize = (10, 15), sharey = True)\n",
        "    ax[0].invert_yaxis()\n",
        "    ax[0].grid()\n",
        "\n",
        "    ax_gr_wrap = ax[0].twiny()\n",
        "    ax_sp_wrap = ax[0].twiny()\n",
        "\n",
        "    ax_rm_wrap = ax[1].twiny()\n",
        "    ax_rd_wrap = ax[1].twiny()\n",
        "\n",
        "    ax_nphi_wrap = ax[2].twiny()\n",
        "\n",
        "    ax[0].plot(logs.CALI, list(range(logs.DEPTH_MD.shape[0])), 'b')\n",
        "    ax_gr_wrap.plot(logs.GR, list(range(logs.DEPTH_MD.shape[0])), 'r')\n",
        "    ax_sp_wrap.plot(logs.SP, list(range(logs.DEPTH_MD.shape[0])), 'g' )\n",
        "\n",
        "    ax[1].plot(logs.RSHA, list(range(logs.DEPTH_MD.shape[0])), 'b')\n",
        "    ax_rm_wrap.plot(logs.RMED, list(range(logs.DEPTH_MD.shape[0])), 'r')\n",
        "    ax_rd_wrap.plot(logs.RDEP, list(range(logs.DEPTH_MD.shape[0])), 'g')\n",
        "\n",
        "    ax[2].plot(logs.RHOB, list(range(logs.DEPTH_MD.shape[0])), 'b')\n",
        "    ax_nphi_wrap.plot(logs.NPHI, list(range(logs.DEPTH_MD.shape[0])), 'r')\n",
        "\n",
        "    ax[3].plot(logs.DTC, list(range(logs.DEPTH_MD.shape[0])), 'b')\n",
        "\n",
        "    ax[0].set_xlim(6, 24)\n",
        "    ax_gr_wrap.set_xlim(0, 150)\n",
        "    ax_sp_wrap.set_xlim(-150, 150)\n",
        "\n",
        "    ax[1].set_xlim(0.2, 200)\n",
        "    ax_rm_wrap.set_xlim(0.2, 200)\n",
        "    ax_rd_wrap.set_xlim(0.2, 200)\n",
        "\n",
        "    ax[1].set_xscale('log')\n",
        "    #ax_rm_wrap.set_xscale('log')\n",
        "    #ax_rd_wrap.set_xscale('log')\n",
        "\n",
        "    ax[2].set_xlim(0.95, 2.95)\n",
        "    ax_nphi_wrap.set_xlim(-0.15, 1.05)\n",
        "    ax_nphi_wrap.invert_xaxis()\n",
        "\n",
        "    ax[3].set_xlim(40, 240)\n",
        "    ax[3].invert_xaxis()\n",
        "\n",
        "    logs_group_temp = logs.GROUP.fillna('N/A')\n",
        "    encoder_temp = LabelEncoder()\n",
        "    encoder_temp.fit(logs_group_temp)\n",
        "    logs_group_temp_encoded = pd.Series(encoder_temp.transform(logs_group_temp))\n",
        "    cl = np.repeat(np.expand_dims(logs_group_temp_encoded.values,1), 200, 1)\n",
        "    ax[4].imshow(cl, interpolation='none', aspect='auto')\n",
        "\n",
        "\n",
        "    ax[4].set_xticklabels([])\n",
        "\n",
        "    xaxis(ax[0], 6, 24, 0, 'b', 'CALI', 10, 1.003)\n",
        "    xaxis(ax_gr_wrap, 0, 150, 25, 'r', 'GR', 10, 1.029)\n",
        "    xaxis(ax_sp_wrap, -150, 150, 50, 'g', 'SP', 10, 1.051)\n",
        "\n",
        "    xaxis(ax[1], 0, 200, 0, 'b', 'Rs', 10, 1.003)\n",
        "    xaxis(ax_rm_wrap, 0.2, 200, 25, 'r', 'Rm', 10, 1.029)\n",
        "    xaxis(ax_rd_wrap, 0.2, 200, 50, 'g', 'Rd', 10, 1.051)\n",
        "\n",
        "    xaxis(ax[2], 0.95, 2.95, 0, 'b', 'RHOB', 10, 1.003)\n",
        "    xaxis(ax_nphi_wrap, -0.15, 1.05, 25, 'r', 'NPHI', 10, 1.029)\n",
        "\n",
        "    xaxis(ax[3], 40, 240, 0, 'b', 'Sonic', 10, 1.003)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyeysdRY2MJX"
      },
      "outputs": [],
      "source": [
        "log_plot(well_train[well_train['WELL'] == '15/9-13'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewJxmO1o2MJX"
      },
      "outputs": [],
      "source": [
        "def log_plot_image(logs,plotname,txtname,i,patch_height):\n",
        "    _, ax = plt.subplots(1,19, figsize = (20, 10), sharey = True, gridspec_kw = {'wspace':0, 'hspace':0})\n",
        "    ax[0].invert_yaxis()\n",
        "    ax[1].invert_yaxis()\n",
        "    ax[2].invert_yaxis()\n",
        "    ax[3].invert_yaxis()\n",
        "    ax[4].invert_yaxis()\n",
        "    ax[5].invert_yaxis()\n",
        "    ax[6].invert_yaxis()\n",
        "    ax[7].invert_yaxis()\n",
        "    ax[8].invert_yaxis()\n",
        "    ax[9].invert_yaxis()\n",
        "    ax[10].invert_yaxis()\n",
        "    ax[11].invert_yaxis()\n",
        "    ax[12].invert_yaxis()\n",
        "    ax[13].invert_yaxis()\n",
        "    ax[14].invert_yaxis()\n",
        "    ax[15].invert_yaxis()\n",
        "    ax[16].invert_yaxis()\n",
        "    ax[17].invert_yaxis()\n",
        "    ax[18].invert_yaxis()\n",
        "\n",
        "\n",
        "    ax[0].plot(logs.CALI[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[0].set_xlim(6, 24)\n",
        "    ax[0].axis('off')\n",
        "    ax[1].plot(logs.GR[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[1].set_xlim(0, 150)\n",
        "    ax[1].axis('off')\n",
        "    ax[2].plot(logs.SP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[2].set_xlim(-150, 150)\n",
        "    ax[2].axis('off')\n",
        "    ax[3].plot(logs.SGR[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[3].set_xlim(0, 150)\n",
        "    ax[3].axis('off')\n",
        "    ax[4].semilogx(logs.RSHA[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[4].set_xlim(2, 200)\n",
        "    ax[4].axis('off')\n",
        "    ax[5].semilogx(logs.RMED[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[5].set_xlim(2, 200)\n",
        "    ax[5].axis('off')\n",
        "    ax[6].semilogx(logs.RDEP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[6].set_xlim(2, 200)\n",
        "    ax[6].axis('off')\n",
        "    ax[7].semilogx(logs.RXO[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[7].set_xlim(2, 200)\n",
        "    ax[7].axis('off')\n",
        "    ax[8].semilogx(logs.RMIC[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[8].set_xlim(2, 200)\n",
        "    ax[8].axis('off')\n",
        "    ax[9].plot(logs.NPHI[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[9].set_xlim(-0.15, 1.05)\n",
        "    ax[9].invert_xaxis()\n",
        "    ax[9].axis('off')\n",
        "    ax[10].plot(logs.RHOB[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[10].set_xlim(0.95, 2.95)\n",
        "    ax[10].invert_xaxis()\n",
        "    ax[10].axis('off')\n",
        "    ax[11].plot(logs.PEF[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[11].set_xlim(0, 10)\n",
        "    ax[11].axis('off')\n",
        "    ax[12].plot(logs.ROP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[12].set_xlim(0, 50)\n",
        "    ax[12].axis('off')\n",
        "    ax[13].plot(logs.ROPA[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[13].set_xlim(0, 50)\n",
        "    ax[13].axis('off')\n",
        "    ax[14].plot(logs.DRHO[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[14].set_xlim(-0.2, 1)\n",
        "    ax[14].axis('off')\n",
        "    ax[15].plot(logs.DTC[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[15].set_xlim(40, 240)\n",
        "    ax[15].invert_xaxis()\n",
        "    ax[15].axis('off')\n",
        "    ax[16].plot(logs.DTS[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[16].set_xlim(40, 240)\n",
        "    ax[16].invert_xaxis()\n",
        "    ax[16].axis('off')\n",
        "    ax[17].plot(logs.MUDWEIGHT[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[17].set_xlim(0, 150)\n",
        "    ax[17].axis('off')\n",
        "    ax[18].plot(logs.BS[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[18].set_xlim(6, 24)\n",
        "    ax[18].axis('off')\n",
        "    \n",
        "     \n",
        "    plt.savefig(plotname,bbox_inches =\"tight\",transparent = False)\n",
        "    #im = Image.open(plotname)\n",
        "    #newsize = (800, 360)\n",
        "    #im = im.resize(newsize)\n",
        "    #im =im.save(plotname)\n",
        "\n",
        "    with open(txtname, 'w', encoding='UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "    # write a row to the csv file\n",
        "        writer.writerow(logs.GROUP[i:i+patch_height][:-1].T)\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bny_YLyi2MJX"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def randon_list_generator():\n",
        "    randomlist = []\n",
        "    for i in range(0,50):\n",
        "        n = random.randint(0,18)\n",
        "        if n not in randomlist:\n",
        "            randomlist.append(n)\n",
        "    if len(randomlist) == 19: \n",
        "        return randomlist\n",
        "    else:\n",
        "        return randon_list_generator()\n",
        "    \n",
        "\n",
        "randomlist = randon_list_generator()\n",
        "print(randomlist)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lP7VXPz2MJX"
      },
      "outputs": [],
      "source": [
        "def log_plot_image_random(logs,plotname,txtname,i,patch_height,randomlist):\n",
        "    _, ax = plt.subplots(1,19, figsize = (20, 10), sharey = True, gridspec_kw = {'wspace':0, 'hspace':0})\n",
        "    j=0\n",
        "    for i in randomlist:\n",
        "        op= log_plots[i]\n",
        "        op(well_train[well_train['WELL'] == well_train_names[0]],ax[j],0,700)\n",
        "        j=j+1\n",
        "    plt.savefig(plotname,bbox_inches =\"tight\",transparent = False)\n",
        "    #im = Image.open(plotname)\n",
        "    #newsize = (800, 360)\n",
        "    #im = im.resize(newsize)\n",
        "    #im =im.save(plotname)\n",
        "\n",
        "    with open(txtname, 'w', encoding='UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        # write a row to the csv file\n",
        "        writer.writerow(logs.GROUP[i:i+patch_height])\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klToEKR52MJY"
      },
      "outputs": [],
      "source": [
        "def log_plot_image_invert(logs,plotname,txtname,i,patch_height):\n",
        "    _, ax = plt.subplots(1,19, figsize = (20, 10), sharey = True, gridspec_kw = {'wspace':0, 'hspace':0})\n",
        "\n",
        "\n",
        "\n",
        "    ax[0].plot(logs.CALI[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[0].set_xlim(6, 24)\n",
        "    ax[0].axis('off')\n",
        "    ax[1].plot(logs.GR[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[1].set_xlim(0, 150)\n",
        "    ax[1].axis('off')\n",
        "    ax[2].plot(logs.SP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[2].set_xlim(-150, 150)\n",
        "    ax[2].axis('off')\n",
        "    ax[3].plot(logs.SGR[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[3].set_xlim(0, 150)\n",
        "    ax[3].axis('off')\n",
        "    ax[4].semilogx(logs.RSHA[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[4].set_xlim(2, 200)\n",
        "    ax[4].axis('off')\n",
        "    ax[5].semilogx(logs.RMED[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[5].set_xlim(2, 200)\n",
        "    ax[5].axis('off')\n",
        "    ax[6].semilogx(logs.RDEP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[6].set_xlim(2, 200)\n",
        "    ax[6].axis('off')\n",
        "    ax[7].semilogx(logs.RXO[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[7].set_xlim(2, 200)\n",
        "    ax[7].axis('off')\n",
        "    ax[8].semilogx(logs.RMIC[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[8].set_xlim(2, 200)\n",
        "    ax[8].axis('off')\n",
        "    ax[9].plot(logs.NPHI[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[9].set_xlim(-0.15, 1.05)\n",
        "    ax[9].invert_xaxis()\n",
        "    ax[9].axis('off')\n",
        "    ax[10].plot(logs.RHOB[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[10].set_xlim(0.95, 2.95)\n",
        "    ax[10].invert_xaxis()\n",
        "    ax[10].axis('off')\n",
        "    ax[11].plot(logs.PEF[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[11].set_xlim(0, 10)\n",
        "    ax[11].axis('off')\n",
        "    ax[12].plot(logs.ROP[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[12].set_xlim(0, 50)\n",
        "    ax[12].axis('off')\n",
        "    ax[13].plot(logs.ROPA[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[13].set_xlim(0, 50)\n",
        "    ax[13].axis('off')\n",
        "    ax[14].plot(logs.DRHO[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[14].set_xlim(-0.2, 1)\n",
        "    ax[14].axis('off')\n",
        "    ax[15].plot(logs.DTC[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[15].set_xlim(40, 240)\n",
        "    ax[15].invert_xaxis()\n",
        "    ax[15].axis('off')\n",
        "    ax[16].plot(logs.DTS[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[16].set_xlim(40, 240)\n",
        "    ax[16].invert_xaxis()\n",
        "    ax[16].axis('off')\n",
        "    ax[17].plot(logs.MUDWEIGHT[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[17].set_xlim(0, 150)\n",
        "    ax[17].axis('off')\n",
        "    ax[18].plot(logs.BS[i:i+patch_height], list(range(i,i+patch_height)), 'b')\n",
        "    ax[18].set_xlim(6, 24)\n",
        "    ax[18].axis('off')\n",
        "    \n",
        "     \n",
        "    plt.savefig(plotname,bbox_inches =\"tight\",transparent = False)\n",
        "    #im = Image.open(plotname)\n",
        "    #newsize = (800, 360)\n",
        "    #im = im.resize(newsize)\n",
        "    #im =im.save(plotname)\n",
        "\n",
        "    with open(txtname, 'w', encoding='UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "    # write a row to the csv file\n",
        "        writer.writerow(logs.GROUP[i:i+patch_height])\n",
        "        f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMxrJCQR2MJY"
      },
      "outputs": [],
      "source": [
        "count =0\n",
        "for j in range(start_well,end_well,1):\n",
        "        well_shape = len(well_train[well_train['WELL'] == well_train_names[j]])\n",
        "        \n",
        "        for i in tqdm(range(0, well_shape, 350)):\n",
        "                plotname = \"well-images/well_\"+str(j)+\"_\"+str(i)+\".jpg\"\n",
        "                txtname = \"well-images/well_\"+str(j)+\"_\"+str(i)+\".csv\"\n",
        "                \n",
        "                if i+700 > well_shape:\n",
        "                        well_not700 = well_shape-i\n",
        "                        #print(i, well_not700+i ,i-(700-well_not700), i-(700-well_not700)+700)\n",
        "                        log_plot_image(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i-(700-well_not700),700)\n",
        "                else:\n",
        "                        log_plot_image(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i,700)\n",
        "                \n",
        "                \n",
        "                        \n",
        "                count = count+1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjZDRiJe2MJY"
      },
      "outputs": [],
      "source": [
        "count =0\n",
        "for j in range(start_well,end_well,1):\n",
        "        well_shape = len(well_train[well_train['WELL'] == well_train_names[j]])\n",
        "        \n",
        "        for i in tqdm(range(0, well_shape, 350)):\n",
        "                plotname = \"well-images/random_well_\"+str(j)+\"_\"+str(i)+\".jpg\"\n",
        "                txtname = \"well-images/random_well_\"+str(j)+\"_\"+str(i)+\".csv\"\n",
        "                randomlist = randon_list_generator()\n",
        "                if i+700 > well_shape:\n",
        "                        well_not700 = well_shape-i\n",
        "                        #print(i, well_not700+i ,i-(700-well_not700), i-(700-well_not700)+700)\n",
        "                        log_plot_image_random(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i-(700-well_not700),700, randomlist)\n",
        "                else:\n",
        "                        log_plot_image_random(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i,700, randomlist)\n",
        "                \n",
        "                \n",
        "                        \n",
        "                count = count+1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McrHyY0q2MJY"
      },
      "outputs": [],
      "source": [
        "count =0\n",
        "for j in range(start_well,end_well,1):\n",
        "        well_shape = len(well_train[well_train['WELL'] == well_train_names[j]])\n",
        "        \n",
        "        for i in tqdm(range(0, well_shape, 350)):\n",
        "                plotname = \"well-images/invert_well_\"+str(j)+\"_\"+str(i)+\".jpg\"\n",
        "                txtname = \"well-images/invert_well_\"+str(j)+\"_\"+str(i)+\".csv\"\n",
        "                \n",
        "                if i+700 > well_shape:\n",
        "                        well_not700 = well_shape-i\n",
        "                        #print(i, well_not700+i ,i-(700-well_not700), i-(700-well_not700)+700)\n",
        "                        log_plot_image_invert(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i-(700-well_not700),700)\n",
        "                else:\n",
        "                        log_plot_image_invert(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i,700)\n",
        "                \n",
        "                \n",
        "                        \n",
        "                count = count+1\n",
        "print(count)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "WellLogCorrelation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "bop",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Oct 12 2021, 13:49:34) \n[GCC 7.5.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "417c89e155f5341f782a743e5d20f9532f43691b968cd62b21a446a5a1478718"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}