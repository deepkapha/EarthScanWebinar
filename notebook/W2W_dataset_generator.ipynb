{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<div align=\"center\"><a href=\"https://colab.research.google.com/github/deepkapha/EarthScanWebinar/blob/main/notebook/W2W_dataset_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a></div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><font size=\"10\">Notebook Outline</font></center>\n",
        "\n",
        "1. **Import Libraries**: In this section, the necessary Python libraries are imported that will be used throughout the notebook.\n",
        "\n",
        "2. **Download Dataset**: This section involves downloading the dataset from a publicly available Google Drive link.\n",
        "\n",
        "3. **Dataset Description**: This section provides a brief description of the dataset that has been downloaded, including its source and format.\n",
        "\n",
        "4. **Exploratory Data Analysis (EDA)**: In this section, the data is analyzed to understand its underlying characteristics. This is an important step in any data analysis project, as it helps to identify patterns, anomalies, and other insights that can inform subsequent analysis.\n",
        "\n",
        "5. **Data Preprocessing**: Once the dataset has been explored, this section involves cleaning and preparing the data for analysis. This may involve handling missing values, or other transformations necessary to ensure that the data is in the appropriate format for analysis.\n",
        "\n",
        "6. **Generating Dataset**: Finally, in this section, the preprocessed data is used to generate a new dataset that can be used for modeling or other purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys \n",
        "sys.path.append('..')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Import the necessaary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import gdown\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import matplotlib.colors as mcolors\n",
        "from os.path import join as pjoin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this cell runs only if you're using \"Open in Colab badge directly from GitHub instead of cloning the Repo or don't have dependencies from ../utils folder\"\n",
        "if not os.path.isdir('../data'):\n",
        "    !curl -OL https://raw.githubusercontent.com/deepkapha/EarthScanWebinar/main/utils/preprocessing.py\n",
        "    !curl -OL https://raw.githubusercontent.com/deepkapha/EarthScanWebinar/main/utils/data_generate.py\n",
        "    !curl -OL https://raw.githubusercontent.com/deepkapha/EarthScanWebinar/main/utils/plot_utils.py\n",
        "    !curl -OL https://raw.githubusercontent.com/deepkapha/EarthScanWebinar/main/utils/well_log_plots.py\n",
        "\n",
        "    !mkdir utils\n",
        "\n",
        "    !mv data_generate.py utils/data_generate.py\n",
        "    !mv plot_utils.py utils/plot_utils.py\n",
        "    !mv preprocessing.py utils/preprocessing.py\n",
        "    !mv well_log_plots.py utils/well_log_plots.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHFWu2TegN-c"
      },
      "outputs": [],
      "source": [
        "from utils import preprocessing, plot_utils, data_generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', 500)\n",
        "overlap = {name for name in mcolors.CSS4_COLORS\n",
        "           if f'xkcd:{name}' in mcolors.XKCD_COLORS}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Download the dataset from publicly avalialable google drive link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_url = 'https://drive.google.com/file/d/1TkRT5TeX7slPDL20OqYqFLhGX5iK4RHc/view?usp=share_link'\n",
        "test_data_url = 'https://drive.google.com/file/d/1ooDiCKweUrduyy0Q1P7KIXnl04BQqH0_/view?usp=share_link'\n",
        "\n",
        "data_root = '../raw_data' if os.path.isdir('../data') else 'raw_data'\n",
        "os.makedirs(data_root, exist_ok = True)\n",
        "train_path = pjoin(data_root, \"train.csv\")\n",
        "test_path = pjoin(data_root, \"test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.isfile(train_path):\n",
        "    gdown.download(url=train_data_url, output=train_path, quiet=False, fuzzy=True)\n",
        "\n",
        "if not os.path.isfile(test_path):\n",
        "    gdown.download(url=test_data_url, output=test_path, quiet=False, fuzzy=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Description of dataset\n",
        "\n",
        "The provided dataset contains well logs, interpreted lithofacies and lithostratigraphy for 90+ released wells from offshore Norway. \n",
        "\n",
        "The well logs include the well name (WELL), the measured depth, x,y,z location for the wireline measurement as well as the well logs CALI, RDEP, RHOB, DHRO, SGR,  GR, RMED, RMIC, NPHI, PEF, RSHA, DTC, SP, BS, ROP, DTS, DCAL, MUDWEIGHT. \n",
        "\n",
        "An explanation of the abbreviations is shown in the figure below. \n",
        "\n",
        "<center>\n",
        "<img src=\"../asset/well_log_abbreviations.png\">\n",
        "\n",
        "source: [Xeek-Challenge/Force-Well-Logs](https://xeek.ai/challenges/force-well-logs)\n",
        "\n",
        "\n",
        "Click [here](https://drive.google.com/drive/folders/1GIkjq4fwgwbiqVQxYwoJnOJWVobZ91pL) to check the results.\n",
        "\n",
        "Given below is the Statistical description of the few important logs from the raw_data\n",
        "\n",
        "\n",
        "| Log Name | min_scale | max_scale | description |\n",
        "|----------|-----------|-----------|-------------|\n",
        "| CALI     |  6        |   24      |             |\n",
        "| GR       |  0        |   150     |             |\n",
        "| SP       |  -150     |   150     |             |\n",
        "| SGR      |  0        |   150     |             |\n",
        "| RSHA     |  0.2      |   200     |             |\n",
        "| RMED     |  0.2      |   200     |             |\n",
        "| RDEP     |  0.2      |   200     |             |\n",
        "| RMIC     |  0.2      | 200 ohm-m |             |\n",
        "| RXO      |  0.2      | 200 ohm-m |             |                 \n",
        "| ROPA     |   0       |    50     |             |\n",
        "| ROP      |   0       |    50     |             |\n",
        "| DTC      |   40       |  240      |             |\n",
        "| DTS      |   40       |  240      |             |\n",
        "| NPHI     |   0.05    |  -0.15    |             |\n",
        "| RHOB     |   0.95    |   2.95    |             |\n",
        "| PEF      |  0        |10 barns/electron|       |             \n",
        "| DCAL     |  6        |    24     |             |\n",
        "| DRHO     |  -0.2     |   1       |             |\n",
        "|MUDWEIGHT |    0       |  150         |             |\n",
        "|BS        |     6      |    24       |             |\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "well_train = preprocessing.load_data(train_path)\n",
        "well_test = preprocessing.load_data(test_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Exploratory Data Analysis (EDA)\n",
        "\n",
        "This section presents the exploratory data analysis performed on the dataset. The objective of EDA is to gain insight into the data, identify patterns, and detect anomalies to inform subsequent analysis.\n",
        "\n",
        "#### Dataset Summary\n",
        "The dataset consists of well log data from oil and gas wells. The training set contains 1,170,511 rows and 29 columns, while the testing set contains 136,786 rows and 27 columns. The data has many multiple wells, with 98 unique wells present in the training set and 10 unique wells present in the testing set. The wells in the training and testing set might or might not have some overlap. We need to investive that as well, hence EDA is required.\n",
        "\n",
        "#### Data Quality Check\n",
        "The data was checked for quality issues such as missing values, duplicated data, and outliers. The following steps were taken:\n",
        "\n",
        "- The FORMATION column, which is not relevant to the analysis, was removed using the remove_formation_column() function.\n",
        "- Missing group information was imputed in each well using the fill_group_na_value() function.\n",
        "- Data with missing values was identified and analyzed for further processing.\n",
        "\n",
        "#### Data Exploration\n",
        "The following steps were taken to explore the dataset:\n",
        "\n",
        "1. The total number of wells present in the dataset was counted using the count_well() function.\n",
        "2. The unique wells present in the training and testing set were identified using the unique() function.\n",
        "3. The count of each well in the training and testing set was plotted using a bar graph.\n",
        "3. Overlapping wells in the training and testing set were identified using the get_overlapping_well() function.\n",
        "4. A random well was selected from the training set using the get_random_well() function and displayed using a table.\n",
        "5. The percentage of missing data in the training and testing set was calculated using the percet_missing_data() function and displayed using a bar graph.\n",
        "6. The unique groups in the training and testing set were identified using the group_identification() function and displayed using a bar graph.\n",
        "7. The groups present in the training and testing set were compared to identify non-overlapping groups using the get_nonoverlapping_groups() function.\n",
        "8. Missing group information was identified in the training and testing set using the missing_group_info() function.\n",
        "\n",
        "\n",
        "The exploration of the data enabled us to gain a better understanding of the dataset and inform subsequent analysis. The analysis and preprocessing of the dataset were performed using Python libraries such as NumPy, Pandas, and Matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPj3VInilSFT"
      },
      "outputs": [],
      "source": [
        "# The code prints out the shape of the training and testing well data, giving an idea of the size of the datasets.\n",
        "print(\"Shape of Well data:\\n\\tTraining Well: {}\\n\\tTesting Well: {}\".format(well_train.shape, well_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNL_xJq-lVx9"
      },
      "outputs": [],
      "source": [
        "# It then counts the total number of wells in each dataset and prints the result, which is useful information to have.\n",
        "total_training_wells = preprocessing.count_well(well_train)\n",
        "total_testing_wells = preprocessing.count_well(well_test)\n",
        "\n",
        "print('Total number of wells present in the dataset:\\n\\tTraining Well: {}\\n\\tTesting Well: {}'.format(total_training_wells, total_testing_wells))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK-UrKMDpFzP"
      },
      "outputs": [],
      "source": [
        "# The unique wells in the training and testing data are identified and plotted as bar charts, giving an idea of the distribution of wells in each dataset.\n",
        "plt.figure(figsize = (25, 5))\n",
        "well_train.WELL.value_counts().plot(kind = 'bar')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The unique wells in the training and testing data are identified and plotted as bar charts, giving an idea of the distribution of wells in each dataset.\n",
        "plt.figure(figsize = (25, 5))\n",
        "well_test.WELL.value_counts().plot(kind = 'bar')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d87ILMdxl8hp"
      },
      "outputs": [],
      "source": [
        "# The code extracts the names of the wells in each dataset and stores them in separate variables.\n",
        "well_train_names = preprocessing.get_well_names(well_train)\n",
        "well_test_names = preprocessing.get_well_names(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwnIH-wmv8Fn"
      },
      "outputs": [],
      "source": [
        "# It identifies any overlapping wells between the training and testing data, and prints the count and names of overlapping wells.\n",
        "# This is important to ensure that if there are wells that are present in both the set.\n",
        "overlapped_well_count, overlapped_well_name = preprocessing.get_overlapping_well(well_train, well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8VxerljmO5B"
      },
      "outputs": [],
      "source": [
        "# A random well from the training data is printed, giving a quick view of the data.\n",
        "preprocessing.get_random_well(well_train, 2020).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hH-PBkWu5d0"
      },
      "outputs": [],
      "source": [
        "# The percentage of missing data for each column in both the training and testing data is calculated and plotted as bar charts, which is useful in identifying columns with high amounts of missing data.\n",
        "percet_missing_train_data = preprocessing.percet_missing_data(well_train)\n",
        "percet_missing_test_data = preprocessing.percet_missing_data(well_test)\n",
        "\n",
        "_, ax = plt.subplots(1, 2, figsize = (20, 4))\n",
        "percet_missing_train_data.plot(kind='bar', ax=ax[0])\n",
        "percet_missing_test_data.plot(kind='bar', ax=ax[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnzKeYdP0SD4"
      },
      "outputs": [],
      "source": [
        "# The code identifies the unique groups in the training and testing data and prints a bar chart of the group distribution in each dataset. \n",
        "# This is important as the groups are the target variable in the machine learning model.\n",
        "training_group = preprocessing.group_identification(well_train)\n",
        "testing_group = preprocessing.group_identification(well_test)\n",
        "\n",
        "training_group_names = training_group.index\n",
        "testing_group_names = testing_group.index\n",
        "\n",
        "_, ax = plt.subplots(1, 2, figsize = (20, 4))\n",
        "training_group.plot(kind='bar', ax=ax[0])\n",
        "testing_group.plot(kind='bar', ax=ax[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn_0h2e54nM3"
      },
      "outputs": [],
      "source": [
        "# It then identifies any non-overlapping groups between the training and testing data and prints the count and names of non-overlapping groups. \n",
        "# This is important to ensure that we don't have any groups in the test wells that ain't found in training wells.\n",
        "nonoverlapped_groups_count, nonoverlapped_groups_name = preprocessing.get_nonoverlapping_groups(training_group_names, testing_group_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EssAvRV5rsCH"
      },
      "outputs": [],
      "source": [
        "# Finally, it checks for any missing group information in both the training and testing data, and prints the count of missing group information for each dataset. \n",
        "# This is important as missing group information needs to be imputed before the machine learning model can be trained.\n",
        "preprocessing.missing_group_info(well_train)\n",
        "preprocessing.missing_group_info(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plots the trajectory of the random well\n",
        "rand_well = preprocessing.get_random_well(well_train, 2023)\n",
        "plot_utils.plot2Dlocation(rand_well)\n",
        "plot_utils.plot3Dlocation(rand_well)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# It checks which wells have missing group information and how many datapoints are missing\n",
        "well_train_with_missing_group_info = preprocessing.get_well_with_missing_group_info(well_train, total_training_wells, well_train_names)\n",
        "well_test_with_missing_group_info = preprocessing.get_well_with_missing_group_info(well_test, total_testing_wells, well_test_names)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Data Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data preprocessing is an important step in any data analysis project as it ensures that the data is accurate and ready for analysis. In this section, we perform several preprocessing steps on our dataset to clean and transform it.\n",
        "\n",
        "A thorough data preprocessing step is crucial to ensure that the data is ready to be fed into machine learning models, which will produce accurate and reliable results.\n",
        "\n",
        "Data processing step in this problem statemet:\n",
        "\n",
        "- The first step is to remove the 'FORMATION' column from both the training and testing datasets. The 'FORMATION' column is not useful for our analysis, and removing it helps to simplify the dataset.\n",
        "\n",
        "- Next, we fill missing 'GROUP' information for some wells in the training dataset using a custom function called 'fill_group_na_value'. The function uses the ffill method to infer the missing group value for the given well. We apply this function to four wells in our training dataset, as they have missing group information.\n",
        "\n",
        "After filling the missing group information, we recheck the training dataset to ensure that no wells still have missing group information. This step is important to ensure that all wells have complete information for subsequent analysis.\n",
        "\n",
        "Overall, these preprocessing steps help to clean and transform the dataset so that it is ready for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjKfHY7aC3j-"
      },
      "outputs": [],
      "source": [
        "# Remove the 'FORMATION' column from both the training and testing datasets, as it is not useful for the analysis.\n",
        "well_train = preprocessing.remove_formation_column(well_train)\n",
        "well_test = preprocessing.remove_formation_column(well_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing 'GROUP' information for some wells in the training dataset using a custom function called 'fill_group_na_value'. \n",
        "# The function uses the ffill method to infer the missing group value for the given well.\n",
        "well_train.loc[well_train['WELL'] == well_train_with_missing_group_info[0], 'GROUP'] = preprocessing.fill_group_na_value(well_train, well_train_with_missing_group_info[0])\n",
        "well_train.loc[well_train['WELL'] == well_train_with_missing_group_info[1], 'GROUP'] = preprocessing.fill_group_na_value(well_train, well_train_with_missing_group_info[1])\n",
        "well_train.loc[well_train['WELL'] == well_train_with_missing_group_info[2], 'GROUP'] = preprocessing.fill_group_na_value(well_train, well_train_with_missing_group_info[2])\n",
        "well_train.loc[well_train['WELL'] == well_train_with_missing_group_info[3], 'GROUP'] = preprocessing.fill_group_na_value(well_train, well_train_with_missing_group_info[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recheck if any wells in the training dataset still have missing 'GROUP' information, and print their names if any. \n",
        "# This step is important to ensure that all wells have complete information for subsequent analysis.\n",
        "preprocessing.get_well_with_missing_group_info(well_train, total_training_wells, well_train_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyeysdRY2MJX"
      },
      "outputs": [],
      "source": [
        "# Plot a log plot for a randomly selected well from the training dataset, using a custom function called 'log_plot'. \n",
        "# This plot is a useful visualization for detecting anomalies in the well logs, which can help in identifying bad data points that need to be cleaned.\n",
        "plot_utils.log_plot(well_train[well_train['WELL'] == preprocessing.get_random_well(well_train, 2000)['WELL'].unique()[0]])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Generating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_well=30\n",
        "end_well=31\n",
        "save_path = '../data' if os.path.isdir('../data') else 'data'\n",
        "img_save_path = pjoin(save_path, 'img')\n",
        "gt_save_path = pjoin(save_path, 'gt')\n",
        "\n",
        "os.makedirs(save_path, exist_ok = True)\n",
        "os.makedirs(img_save_path, exist_ok = True)\n",
        "os.makedirs(gt_save_path, exist_ok = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_dataset(well_train, well_train_names, start_well, end_well, img_save_path, gt_save_path, plot_type):\n",
        "    \"\"\"Generates a dataset of images and ground truth files.\n",
        "\n",
        "    Args:\n",
        "        well_train (pandas.DataFrame): The training well data.\n",
        "        well_train_names (list of str): The names of the training wells.\n",
        "        start_well (int): The index of the first well to include.\n",
        "        end_well (int): The index of the last well to include.\n",
        "        plot_type (str): The type of plots to generate. Must be one of: 'normal', 'random', 'invert'.\n",
        "        img_save_path (str): The path to save the generated images.\n",
        "        gt_save_path (str): The path to save the generated ground truth files.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    for j in range(start_well,end_well,1):\n",
        "        well_shape = len(well_train[well_train['WELL'] == well_train_names[j]])\n",
        "        for i in tqdm(range(0, well_shape, 350)):\n",
        "            if plot_type == 'normal':\n",
        "                prefix = \"\"\n",
        "            elif plot_type == 'random':\n",
        "                randomlist = data_generate.randon_list_generator()\n",
        "                prefix = \"random_\"\n",
        "            elif plot_type == 'invert':\n",
        "                prefix = \"invert_\"\n",
        "            else:\n",
        "                print(f\"Select plot_type from [normal, random, invert]. plot_type {plot_type} doesn't exist\")\n",
        "                return\n",
        "\n",
        "            plotname = pjoin(img_save_path, prefix+\"well_\"+str(j)+\"_\"+str(i)+\".jpg\")\n",
        "            txtname = pjoin(gt_save_path, prefix+\"well_\"+str(j)+\"_\"+str(i)+\".csv\")\n",
        "\n",
        "            if i+700 > well_shape:\n",
        "                well_not700 = well_shape-i\n",
        "                if plot_type == 'normal':\n",
        "                    data_generate.log_plot_image(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i-(700-well_not700),700)\n",
        "                elif plot_type == 'random':\n",
        "                    data_generate.log_plot_image_random(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i-(700-well_not700),700, randomlist,well_train,well_train_names)\n",
        "                elif plot_type == 'invert':\n",
        "                    data_generate.log_plot_image_invert(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i-(700-well_not700),700)\n",
        "                else:\n",
        "                    print(f\"Select plot_type from [normal, random, invert]. plot_type {plot_type} doesn't exist\")\n",
        "                    return\n",
        "            else:\n",
        "                if plot_type == 'normal':\n",
        "                    data_generate.log_plot_image(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i,700)\n",
        "                elif plot_type == 'random':\n",
        "                    data_generate.log_plot_image_random(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i,700, randomlist,well_train,well_train_names)\n",
        "                elif plot_type == 'invert':\n",
        "                    data_generate.log_plot_image_invert(well_train[well_train['WELL'] == well_train_names[0]],plotname,txtname,i,700)\n",
        "                else:\n",
        "                    print(f\"Select plot_type from [normal, random, invert]. plot_type {plot_type} doesn't exist\")\n",
        "                    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_dataset(well_train, well_train_names, start_well, end_well, img_save_path, gt_save_path, plot_type = 'normal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_dataset(well_train, well_train_names, start_well, end_well, img_save_path, gt_save_path, plot_type = 'random')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_dataset(well_train, well_train_names, start_well, end_well, img_save_path, gt_save_path, plot_type = 'invert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "WellLogCorrelation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3dd02822eec6e63246b4c31a92e4c6595d15d42a17bcd9ad457f6129f597c73c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
